<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.3.0',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="把我的过程记录下来，以免以后忘了">
<meta property="og:type" content="website">
<meta property="og:title" content="Fearchen&#39;s Blog">
<meta property="og:url" content="http://fearchen.github.io/page/4/index.html">
<meta property="og:site_name" content="Fearchen&#39;s Blog">
<meta property="og:description" content="把我的过程记录下来，以免以后忘了">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fearchen&#39;s Blog">
<meta name="twitter:description" content="把我的过程记录下来，以免以后忘了">






  <link rel="canonical" href="http://fearchen.github.io/page/4/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Fearchen's Blog</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-right 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Fearchen's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">把我的过程记录下来，以免以后忘了</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于</a>
  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fearchen.github.io/2018/04/25/OpenShift-运维管理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen Fei">
      <meta itemprop="description" content="把我的过程记录下来，以免以后忘了">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fearchen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/25/OpenShift-运维管理/" itemprop="url">
                  OpenShift-运维管理
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-04-25 09:51:07 / 修改时间：10:05:15" itemprop="dateCreated datePublished" datetime="2018-04-25T09:51:07+08:00">2018-04-25</time>
            

            
              

              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/OpenShift/" itemprop="url" rel="index"><span itemprop="name">OpenShift</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Cockpit介绍"><a href="#Cockpit介绍" class="headerlink" title="Cockpit介绍"></a>Cockpit介绍</h2><p>Cockpit是一个开源的系统管理项目，其目的是为用户提供一个灵活高效的Linux系统运维管理界面。目前Cockpit支持Docker、Kubernetes和OpenShift。通过Cockpit，用户可以在一个统一的系统中获取OpenShift集群节点操作系统的实时信息及配置，用户也可以在Cockpit中以管理员的身份对OpenShift集群进行管理。</p>
<p>项目URL：<a href="https://github.com/cockpit-project" target="_blank" rel="noopener">https://github.com/cockpit-project</a></p>
<h2 id="Cockpit部署"><a href="#Cockpit部署" class="headerlink" title="Cockpit部署"></a>Cockpit部署</h2><ul>
<li>所有节点执行</li>
</ul>
<table>
<thead>
<tr>
<th>yum install cockpit cockpit-docker cockpit-kubernetes -y</th>
</tr>
</thead>
<tbody>
<tr>
<td>systemctl start cockpit &amp;&amp; systemctl enable cockpit</td>
</tr>
<tr>
<td>vim /etc/sysconfig/iptables</td>
</tr>
<tr>
<td>A INPUT -p tcp -m state –state NEW -m tcp –dport 9090 -j ACCEPT</td>
</tr>
<tr>
<td><a href="./media/image1.png">./media/image1.png</a></td>
</tr>
<tr>
<td>systemctl restart iptables</td>
</tr>
</tbody>
</table>
<ul>
<li>登陆</li>
</ul>
<table>
<thead>
<tr>
<th>登陆<a href="https://master.example.com:9090/" target="_blank" rel="noopener">https://master.example.com:9090/</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>用户名密码即服务器用户名密码</td>
</tr>
<tr>
<td><a href="./media/image2.png">./media/image2.png</a></td>
</tr>
<tr>
<td><a href="./media/image3.png">./media/image3.png</a></td>
</tr>
</tbody>
</table>
<h2 id="Cockpit集群运维"><a href="#Cockpit集群运维" class="headerlink" title="Cockpit集群运维"></a>Cockpit集群运维</h2><table>
<thead>
<tr>
<th>在集群选项中可以添加OpenShift集群</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image4.png">./media/image4.png</a></td>
</tr>
<tr>
<td>各信息在浏览器中直观展现</td>
</tr>
<tr>
<td>节点</td>
</tr>
<tr>
<td><a href="./media/image5.png">./media/image5.png</a></td>
</tr>
<tr>
<td>拓扑</td>
</tr>
<tr>
<td><a href="./media/image6.png">./media/image6.png</a></td>
</tr>
<tr>
<td>持久化卷</td>
</tr>
<tr>
<td><a href="./media/image7.png">./media/image7.png</a></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h2 id="OpenShift集群扩容"><a href="#OpenShift集群扩容" class="headerlink" title="OpenShift集群扩容"></a>OpenShift集群扩容</h2><p>根据OpenShift项目官方资料，单个计算节点可以支持250个Pod，单一集群目前实际最大部署数量达到1000个节点，单一集群的最大Pod数量为120<br>000。</p>
<p>目前集群扩容的方式有：</p>
<ul>
<li>半自动扩容：</li>
</ul>
<blockquote>
<p>  OpenShift默认提供了扩容的Ansible<br>  Playbook解决自动化节点的安装和配置，之所以称为半自动，是因为Ansible扩容的时机是由用户决定的。</p>
</blockquote>
<ul>
<li>全自动扩容：</li>
</ul>
<blockquote>
<p>  自动扩容是在半自动扩容的基础上由系统自动判别当前集群资源是否足够，如果不足，则调用Ansible<br>  Playbook进行扩容。自动扩容需要ManageIQ第三方云管理平台的支持，根据用户预定义的规则，在满足规则条件的情况下对集群进行扩容或缩容。</p>
</blockquote>
<h3 id="Ansible-Playbook"><a href="#Ansible-Playbook" class="headerlink" title="Ansible Playbook"></a>Ansible Playbook</h3><p>通过Ansible<br>Playboko进行扩容需要编辑Ansible的Inventory，/etc/ansible/hosts文件，在相应角色下添加新节点的域名以及配置信息</p>
<table>
<thead>
<tr>
<th># host group for masters [masters] master.example.com # host group for etcd [etcd] master.example.com # host group for nodes, includes region info [nodes] master.example.com node1.example.com openshift_node_labels=”{‘region’: ‘primary’, ‘zone’: ‘east’}” node2.example.com openshift_node_labels=”{‘region’: ‘primary’, ‘zone’: ‘west’}” infra-node1.example.com openshift_node_labels=”{‘region’: ‘infra’, ‘zone’: ‘default’}” infra-node2.example.com openshift_node_labels=”{‘region’: ‘infra’, ‘zone’: ‘default’}” #新增计算节点 node3.example.com node4.example.com</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h3 id="主节点扩容Playbook"><a href="#主节点扩容Playbook" class="headerlink" title="主节点扩容Playbook"></a>主节点扩容Playbook</h3><table>
<thead>
<tr>
<th>ansible-playbook /root/openshift-ansible/playbooks/byo/openshift-master/scaleup.yml</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h3 id="计算节点扩容Playbook"><a href="#计算节点扩容Playbook" class="headerlink" title="计算节点扩容Playbook"></a>计算节点扩容Playbook</h3><table>
<thead>
<tr>
<th>ansible-playbook /root/openshift-ansible/playbooks/byo/openshift-node/scaleup.yml</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h2 id="OpenShift集群缩容"><a href="#OpenShift集群缩容" class="headerlink" title="OpenShift集群缩容"></a>OpenShift集群缩容</h2><p>缩容是指减小集群的计算资源，缩容主要考虑如何将计算资源抽离集群而不影响现有的业务。在缩容的场景中，集群管理员需要保证：1.新的容器不会再创建于要缩减的计算之上；2.当前运行在计划缩减的计算节点之上的容器能迁移到其他计算节点之上。</p>
<h3 id="禁止参与调度"><a href="#禁止参与调度" class="headerlink" title="禁止参与调度"></a>禁止参与调度</h3><table>
<thead>
<tr>
<th>控制一个计算节点是否参与到集群的调度运行应用</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc adm manage-node master.example.com –schedulable=false</td>
</tr>
<tr>
<td><a href="./media/image8.png">./media/image8.png</a></td>
</tr>
</tbody>
</table>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fearchen.github.io/2018/04/25/OpenShift-性能监控/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen Fei">
      <meta itemprop="description" content="把我的过程记录下来，以免以后忘了">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fearchen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/25/OpenShift-性能监控/" itemprop="url">
                  OpenShift-性能监控
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-04-25 09:51:07 / 修改时间：10:05:03" itemprop="dateCreated datePublished" datetime="2018-04-25T09:51:07+08:00">2018-04-25</time>
            

            
              

              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/OpenShift/" itemprop="url" rel="index"><span itemprop="name">OpenShift</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>OpenShift在Kubernetes架构的基础上提供了一套易于使用的度量采集和性能监控方案。设计从整个环境中的容器、POD、Node节点中收集信息，然后在Web控制台中显示这些信息。</p>
<blockquote>
<p>  项目URL：<a href="https://github.com/openshift/origin-metrics" target="_blank" rel="noopener">https://github.com/openshift/origin-metrics</a></p>
</blockquote>
<p>主要通过以下组件实现：</p>
<ul>
<li>Heapster</li>
</ul>
<blockquote>
<p>  Heapster通过Master<br>  API收集系统级别的信息，如CPU、内存、网络，然后将这些信息发送到Hawkular</p>
</blockquote>
<blockquote>
<p>  <a href="https://github.com/kubernetes/heapster" target="_blank" rel="noopener">https://github.com/kubernetes/heapster</a></p>
</blockquote>
<ul>
<li>Hawkular Metrics</li>
</ul>
<blockquote>
<p>  Hawkular Metrics是来此Hawkular项目的监控存储引擎。它提供了通过json<br>  REST接口来创建、访问和管理历史存储指标的方法。</p>
</blockquote>
<blockquote>
<p>  <a href="https://github.com/hawkular/hawkular-metrics" target="_blank" rel="noopener">https://github.com/hawkular/hawkular-metrics</a></p>
</blockquote>
<ul>
<li>Cassandra</li>
</ul>
<blockquote>
<p>  Cassandra是Hawkular的分布式数据库</p>
</blockquote>
<p><a href="http://cassandra.apache.org/" target="_blank" rel="noopener">http://cassandra.apache.org/</a></p>
<ul>
<li>Hawkular OpenShift Agent</li>
</ul>
<blockquote>
<p>  Hawkular OpenShift<br>  Agent是一个代理组件，用来收集来此pod的应用程序级别的数据。前提是pod公开自己希望被收集的信息。</p>
</blockquote>
<p><img src="media/6e089fd62397d30c1533bb14d818b607.jpg" alt=""></p>
<p>OpenShift的监控采集方案的组件Heapster、Hawkular<br>Metrics、Canssandra数据库都是以容器的形式提供，并默认提供了可快速部署的Temaplate。</p>
<h2 id="启用集群监控"><a href="#启用集群监控" class="headerlink" title="启用集群监控"></a>启用集群监控</h2><p>版本1.4之前OpenShift<br>Origin提供template的方式，供用户安装Metrics组件，从版本1.5开始到当前环境的3.6版本，OpenShift<br>Origin开始已Ansible Playbook的方式安装Metris组件。</p>
<p>Playbook URL：./openshift-ansible/playbooks/common/openshift-cluster/<br>openshift_metrics.yml</p>
<table>
<thead>
<tr>
<th>由于部署需要联网下载docker 镜像，网络原因导致失败，提前下载。</th>
</tr>
</thead>
<tbody>
<tr>
<td>在infra-node上下载以下镜像，并保证infrra-node物理内存>4G</td>
</tr>
<tr>
<td>docker pull docker.io/openshift/origin-metrics-heapster:latest docker pull docker.io/openshift/origin-metrics-hawkular-metrics:latest docker pull docker.io/openshift/origin-metrics-heapster:lates</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>开始部署Metric组件</td>
</tr>
<tr>
<td>ansible-playbook /root/openshift-ansible/playbooks/byo/openshift-cluster/openshift-metrics.yml \ -e openshift_metrics_install_metrics=True \ -e openshift_metrics_hawkular_hostname=hawkular-metrics.example.com</td>
</tr>
<tr>
<td>因为测试使用临时存储，若要持久化存储： ansible-playbook /root/openshift-ansible/playbooks/byo/openshift-cluster/openshift-metrics.yml \ -e openshift_metrics_install_metrics=True \ -e openshift_metrics_hawkular_hostname=hawkular-metrics.example.com \ -e openshift_metrics_cassandra_storage_type=pv</td>
</tr>
<tr>
<td><a href="./media/image2.png">./media/image2.png</a></td>
</tr>
<tr>
<td>oc project openshift-infra</td>
</tr>
<tr>
<td>oc get po</td>
</tr>
<tr>
<td><a href="./media/image3.png">./media/image3.png</a></td>
</tr>
</tbody>
</table>
<h2 id="使用集群监控"><a href="#使用集群监控" class="headerlink" title="使用集群监控"></a>使用集群监控</h2><table>
<thead>
<tr>
<th>部署完成后，在OpenShift的Web控制台，进入某一个Pod的详情页面，单机Metrics页签，可以看到当前Pod的CPU，内存及网络的使用情况，如下图</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p><img src="media/723b74430b2819fc8b4f872e804a4d8f.png" alt=""></p>
<h2 id="集群监控容量规划"><a href="#集群监控容量规划" class="headerlink" title="集群监控容量规划"></a>集群监控容量规划</h2><p>OpenShift<br>Origin监控存储使用的是Cassandra数据库。默认设置，监控数据存储七天，七天后，Cassandra开始清除旧数据。已删除的Pod和Project的监控数据不会自动清除，只要超过7天才会被删除</p>
<table>
<thead>
<tr>
<th>Pod运行累计数据表</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>1000Pod</td>
<td>10000Pod</td>
</tr>
<tr>
<td>24小时Cassandra数据占用</td>
<td>2.5GB</td>
<td>11.4GB</td>
</tr>
<tr>
<td>7天Cassandra数据占用</td>
<td>20GB</td>
<td>90GB</td>
</tr>
</tbody>
</table>
<h2 id="监控组件配置"><a href="#监控组件配置" class="headerlink" title="监控组件配置"></a>监控组件配置</h2><p>在实际环境中，强烈建议为Cassandra数据库配置后端持久化存储，并且规划好容量。此外根据集群以及应用规模，可以调整Hawkular<br>Metrics及Cassandra数据库的实例数量，保证性能及相应速度。</p>
<p>详细关于监控的配置项，参考官方文档：<a href="https://docs.openshift.org/3.6/install_config/cluster_metrics.html" target="_blank" rel="noopener">https://docs.openshift.org/3.6/install_config/cluster_metrics.html</a></p>
<h2 id="监控接口"><a href="#监控接口" class="headerlink" title="监控接口"></a>监控接口</h2><p>OpenShift的监控信息最终都存放在Hawkular<br>Metrics后端的Cassandra数据库中。可以访问Hawkular<br>Metrics的RESTful接口获取其中的信息，着对需要将OpenShift的监控和企业现有监控对接有很大帮助。</p>
<p>Heapster已配置通过API访问，并且需要cluster-reader或cluster-admin权限。</p>
<table>
<thead>
<tr>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>curl -H “Authorization: Bearer \$(oc whoami -t)” \ -X GET https://\${KUBERNETES_MASTER}/api/v1/proxy/namespaces/openshift-infra/services/https:heapster:/validate</td>
</tr>
</tbody>
</table>
<p>更多API接口信息，参考Heapster项目：</p>
<p><a href="https://github.com/kubernetes/heapster/" target="_blank" rel="noopener">https://github.com/kubernetes/heapster/</a></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fearchen.github.io/2018/04/25/OpenShift-日志管理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen Fei">
      <meta itemprop="description" content="把我的过程记录下来，以免以后忘了">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fearchen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/25/OpenShift-日志管理/" itemprop="url">
                  OpenShift-日志管理
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-04-25 09:51:07 / 修改时间：10:04:50" itemprop="dateCreated datePublished" datetime="2018-04-25T09:51:07+08:00">2018-04-25</time>
            

            
              

              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/OpenShift/" itemprop="url" rel="index"><span itemprop="name">OpenShift</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简介"><a href="#简介" class="headerlink" title="简介 "></a>简介 </h2><p>OpenShift平台的日志聚合和管理是在EFK方案的基础上实现的。EFK主要汇集来自Host和App的运行日志，包括多个容器和已删除的Pods。</p>
<p>EFK Stack是在EFK上修改的版本，由以下部分组成：</p>
<ul>
<li><p>Elasticsearch：存储所有日志的额对象存储</p>
</li>
<li><p>Fluentd：从节点收集日志并推送给ES</p>
</li>
<li><p>Kibana：ES的Web UI</p>
</li>
<li><p>Curator：从ES删除旧日志</p>
</li>
</ul>
<h2 id="部署EFK-Stack"><a href="#部署EFK-Stack" class="headerlink" title="部署EFK Stack"></a>部署EFK Stack</h2><p>EFK Stack使用Ansible Playbook部署日志管理组件。</p>
<p>origin-logging-elasticsearch服务至少需要有物理内存8G的Node节点</p>
<table>
<thead>
<tr>
<th>由于网络原因，提前下载images</th>
</tr>
</thead>
<tbody>
<tr>
<td>docker pull docker.io/openshift/origin-logging-fluentd:latest</td>
</tr>
<tr>
<td>docker pull openshift/origin-logging-curator:latest</td>
</tr>
<tr>
<td>docker pull openshift/origin-logging-kibana:latest</td>
</tr>
<tr>
<td>docker pull openshift/origin-logging-elasticsearch:latest</td>
</tr>
<tr>
<td>ansible-playbook /root/openshift-ansible/playbooks/byo/openshift-cluster/openshift-logging.yml</td>
</tr>
<tr>
<td><a href="./media/image1.png">./media/image1.png</a></td>
</tr>
<tr>
<td>验证服务正常</td>
</tr>
<tr>
<td><a href="./media/image2.png">./media/image2.png</a></td>
</tr>
</tbody>
</table>
<h2 id="访问Kibana"><a href="#访问Kibana" class="headerlink" title="访问Kibana"></a>访问Kibana</h2><p>通过Route创建的URL进行访问：<a href="https://kibana.router.default.svc.cluster.local/" target="_blank" rel="noopener">https://kibana.router.default.svc.cluster.local/</a></p>
<p>（配置好DNS或者Hosts）</p>
<table>
<thead>
<tr>
<th><a href="./media/image3.png">./media/image3.png</a></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h2 id="日志管理操作"><a href="#日志管理操作" class="headerlink" title="日志管理操作"></a>日志管理操作</h2><ol>
<li>允许集群成员查看集群日志</li>
</ol>
<blockquote>
<p>  默认情况下，只有集群管理员才能访问日志管理，若要允许普通成员访问则需要开启配置</p>
</blockquote>
<table>
<thead>
<tr>
<th>oc project logging</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc edit configmap/logging-elasticsearch</td>
</tr>
<tr>
<td>openshift.operations.allow_cluster_reader 配置为true</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td><a href="./media/image4.png">./media/image4.png</a></td>
</tr>
<tr>
<td>或者在部署前修改playbbok</td>
</tr>
<tr>
<td>vim /root/openshift-ansible/roles/openshift_logging/defaults/main.yml</td>
</tr>
<tr>
<td>openshift_logging_es_allows_cluster_reader配置true</td>
</tr>
<tr>
<td><a href="./media/image5.png">./media/image5.png</a></td>
</tr>
</tbody>
</table>
<ol>
<li>Fluentd</li>
</ol>
<blockquote>
<p>  Fluentd使用Systemd Journal作为日志源，默认情况下，Fluentd分别从/ var / log /<br>  messages和<br>  /var/log/containers/\&lt;container>.log中读取系统日志和容器日志。您可以改为使用systemd日志作为日志源。有三个库存参数可用：</p>
</blockquote>
<table>
<thead>
<tr>
<th>参数</th>
<th>概述</th>
</tr>
</thead>
<tbody>
<tr>
<td>openshift_logging_use_journal</td>
<td>缺省值为空，它配置Fluentd以检查Docker正在使用哪个日志驱动程序。如果Docker正在使用–log-driver=journald，Fluentd将从systemd日志中读取数据，否则，它会假定docker正在使用json-file日志驱动程序并从/ var / log文件源读取数据。您可以将openshift_logging_use_journal选项指定 为true或false明确指出要使用哪个日志源。使用systemd日志需要docker-1.10或更高版本，并且必须配置Docker以使用–log-driver=journald。</td>
</tr>
<tr>
<td>openshift_logging_journal_read_from_head</td>
<td>如果此设置为false，Fluentd将从日志末尾开始读取，忽略历史日志。如果这个设置是true，Fluentd开始从日志的开头读取日志。</td>
</tr>
</tbody>
</table>
<ol>
<li>修改kibana URL</li>
</ol>
<table>
<thead>
<tr>
<th>/etc/origin/master/master-config.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>… assetConfig: … loggingPublicURL: “<a href="https://kibana.example.com&quot;" target="_blank" rel="noopener">https://kibana.example.com&quot;</a> …</td>
</tr>
<tr>
<td>必须为https</td>
</tr>
<tr>
<td>oc scale dc/logging-kibana –replicas=2</td>
</tr>
</tbody>
</table>
<ol start="2">
<li>Curator配置</li>
</ol>
<blockquote>
<p>  Curator允许管理员配置按计划自动执行的预定Elasticsearch维护操作。它计划每天根据其配置执行操作。每个Elasticsearch群集只推荐一个Curator<br>  pod，配置参数</p>
</blockquote>
<table>
<thead>
<tr>
<th>变量名</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>\$PROJECT_NAME</td>
<td>项目的实际名称，例如myapp-devel。对于OpenShift Origin 操作 日志，请使用该名称.operations作为项目名称。</td>
</tr>
<tr>
<td>\$ACTION</td>
<td>目前只delete允许采取行动。</td>
</tr>
<tr>
<td>\$UNIT</td>
<td>其中一个days，weeks或months。</td>
</tr>
<tr>
<td>\$VALUE</td>
<td>单位数的整数。</td>
</tr>
<tr>
<td>.defaults</td>
<td>使用.defaults的\$PROJECT_NAME设置为未指定的项目的默认值。</td>
</tr>
<tr>
<td>runhour</td>
<td>（数量）以24小时格式运行策展人作业的一天中的小时。用于.defaults。</td>
</tr>
<tr>
<td>runminute</td>
<td>（数字）运行策展人作业的小时数。用于.defaults。</td>
</tr>
<tr>
<td>例如，要将Curator配置为：</td>
</tr>
</tbody>
</table>
<ul>
<li><p>删除比<strong>myapp-dev</strong>项目早的索引1 day</p>
<ul>
<li><p>删除<strong>myapp-qe</strong>项目中早于的索引1 week</p>
<ul>
<li><p>删除<strong>操作</strong>日志比8 weeks</p>
<ul>
<li><p>删除30 days旧的所有其他项目索引</p>
</li>
<li><p>每天午夜运行策展人工作</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>使用： MYAPP-dev的： 删除： 天数：1 MYAPP - 即： 删除： 周：1 .operations： 删除： 周：8 .defaults： 删除： 天数：30 runhour: 0 runminute：0</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>创建curator配置</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>编辑提供的ConfigMap</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>oc edit configmap/logging-curator</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>代替提供的ConfigMap：</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>create /path/to/mycuratorconfig.yaml oc create configmap logging-curator -o yaml \ –from-file=config.yaml=/path/to/mycuratorconfig.yaml \</td>
<td>\ oc replace -f -</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>完成更改后，重新部署</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>oc rollout latest dc/logging-curator oc rollout latest dc/logging-curator-ops</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fearchen.github.io/2018/04/25/OpenShift-企业应用-3.6.1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen Fei">
      <meta itemprop="description" content="把我的过程记录下来，以免以后忘了">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fearchen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/25/OpenShift-企业应用-3.6.1/" itemprop="url">
                  OpenShift-企业应用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-04-25 09:51:07 / 修改时间：10:04:37" itemprop="dateCreated datePublished" datetime="2018-04-25T09:51:07+08:00">2018-04-25</time>
            

            
              

              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/OpenShift/" itemprop="url" rel="index"><span itemprop="name">OpenShift</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Ansible部署"><a href="#Ansible部署" class="headerlink" title="Ansible部署"></a>Ansible部署</h2><p><strong>为区分各角色，部署结构如下：</strong></p>
<h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><table>
<thead>
<tr>
<th>主机名</th>
<th>角色</th>
<th>IP地址</th>
<th>操作系统</th>
<th>硬件配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>master.example.com</td>
<td>master</td>
<td>10.10.31.161</td>
<td>7.4 mini</td>
<td>4C2G+30G</td>
</tr>
<tr>
<td>node1.example.com</td>
<td>node</td>
<td>10.10.31.162</td>
<td>7.4 mini</td>
<td>4C2G+30G</td>
</tr>
<tr>
<td>node2.example.com</td>
<td>node</td>
<td>10.10.31.163</td>
<td>7.4 mini</td>
<td>4C2G+30G</td>
</tr>
<tr>
<td>infra-node1.example.com</td>
<td>node</td>
<td>10.10.31.164</td>
<td>7.4 mini</td>
<td>4C2G+30G</td>
</tr>
<tr>
<td>infra-node2.example.com</td>
<td>node</td>
<td>10.10.31.165</td>
<td>7.4 mini</td>
<td>4C2G+30G</td>
</tr>
</tbody>
</table>
<h3 id="准备工作，所有主机执行"><a href="#准备工作，所有主机执行" class="headerlink" title="准备工作，所有主机执行"></a>准备工作，所有主机执行</h3><table>
<thead>
<tr>
<th>配置主机名</th>
</tr>
</thead>
<tbody>
<tr>
<td>hostnamectl set-hostname master.example.com hostnamectl set-hostname node1.example.com hostnamectl set-hostname node2.example.com hostnamectl set-hostname infra-node1.example.com hostnamectl set-hostname infra-node2.example.com</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>若无DNS Server，则配置Hosts</td>
</tr>
<tr>
<td>10.10.31.161 master.example.com 10.10.31.162 node1.example.com 10.10.31.163 node2.example.com 10.10.31.164 infra-node1.example.com 10.10.31.165 infra-node2.example.com</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>确认网络正常</td>
</tr>
<tr>
<td>nmcli con show nmcli con up ens160 nmcli con mod ens160 connection.autoconnect yes systemctl restart NetworkManager systemctl status NetworkManager systemctl is-enabled NetworkManager</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>安装基础软件包</td>
</tr>
<tr>
<td>yum install wget git net-tools bind-utils iptables-services bridge-utils bash-completion kexec-tools sos psacct -y</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>升级系统</td>
</tr>
<tr>
<td>yum update -y</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>安装Docker</td>
</tr>
<tr>
<td>yum install docker -y</td>
</tr>
<tr>
<td>docker version</td>
</tr>
<tr>
<td>配置docker后端存储</td>
</tr>
<tr>
<td>cat \&lt;\<eof \=""> /etc/sysconfig/docker-storage-setup DEVS=/dev/sdb EOF</eof></td>
</tr>
<tr>
<td>docker-storage-setup</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>添加中科大源</td>
</tr>
<tr>
<td>vim /etc/docker/daemon.json</td>
</tr>
<tr>
<td>{ “registry-mirrors”: [“<a href="https://docker.mirrors.ustc.edu.cn/&quot;]" target="_blank" rel="noopener">https://docker.mirrors.ustc.edu.cn/&quot;]</a> }</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>systemctl enable docker &amp;&amp; systemctl start docker</td>
</tr>
</tbody>
</table>
<h3 id="配置Ansible，Master执行"><a href="#配置Ansible，Master执行" class="headerlink" title="配置Ansible，Master执行"></a>配置Ansible，Master执行</h3><p>由于网络原因，提前修改repo源和导入docker images</p>
<table>
<thead>
<tr>
<th>配置EPEL</th>
</tr>
</thead>
<tbody>
<tr>
<td>yum -y install \ <a href="https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm" target="_blank" rel="noopener">https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</a></td>
</tr>
<tr>
<td>不启用EPEL，后续手动指定</td>
</tr>
<tr>
<td>sed -i -e “s/\^enabled=1/enabled=0/“ /etc/yum.repos.d/epel.repo</td>
</tr>
<tr>
<td>安装Ansible</td>
</tr>
<tr>
<td>yum -y –enablerepo=epel install ansible pyOpenSSL</td>
</tr>
<tr>
<td>拉取最新openshift-ansible版本</td>
</tr>
<tr>
<td>cd ~ git clone -b release-3.6 <a href="https://github.com/openshift/openshift-ansible.git" target="_blank" rel="noopener">https://github.com/openshift/openshift-ansible.git</a> cd openshift-ansible</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>修改ansible playbook中的repo源</td>
</tr>
<tr>
<td>vim openshift-ansible/roles/openshift_repos/templates/CentOS-OpenShift-Origin36.repo.j2</td>
</tr>
<tr>
<td>baseurl=<a href="http://mirrors.ustc.edu.cn/centos/7.4.1708/paas/x86_64/openshift-origin36/" target="_blank" rel="noopener">http://mirrors.ustc.edu.cn/centos/7.4.1708/paas/x86_64/openshift-origin36/</a></td>
</tr>
<tr>
<td><a href="./media/image1.png">./media/image1.png</a></td>
</tr>
<tr>
<td>提前pull好docker images</td>
</tr>
<tr>
<td><a href="./media/image2.png">./media/image2.png</a></td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>配置各主机互信</td>
</tr>
<tr>
<td>ssh-keygen -f /root/.ssh/id_rsa -N ‘’</td>
</tr>
<tr>
<td>for host in master.example.com \ etcd.example.com \ node2.example.com \ node1.example.com \ infra-node1.example.com \ infra-node2.example.com; do ssh-copy-id -i ~/.ssh/id_rsa.pub \$host; done</td>
</tr>
</tbody>
</table>
<h3 id="执行部署"><a href="#执行部署" class="headerlink" title="执行部署"></a>执行部署</h3><ul>
<li>准备Ansible Host</li>
</ul>
<table>
<thead>
<tr>
<th>mv -f /etc/ansible/hosts /etc/ansible/hosts.old</th>
</tr>
</thead>
<tbody>
<tr>
<td>vi /etc/ansible/hosts</td>
</tr>
<tr>
<td># Create an OSEv3 group that contains the masters and nodes groups [OSEv3:children] masters nodes etcd # Set variables common for all OSEv3 hosts [OSEv3:vars] # SSH user, this user should allow ssh based auth without requiring a password ansible_ssh_user=root # If ansible_ssh_user is not root, ansible_become must be set to true #ansible_become=true openshift_deployment_type=origin # uncomment the following to enable htpasswd authentication; defaults to DenyAllPasswordIdentityProvider openshift_master_identity_providers=[{‘name’: ‘htpasswd_auth’, ‘login’: ‘true’, ‘challenge’: ‘true’, ‘kind’: ‘HTPasswdPasswordIdentityProvider’, ‘filename’: ‘/etc/origin/master/htpasswd’}] #Disable disk and memory checks openshift_disable_check=disk_availability,memory_availability # host group for masters [masters] master.example.com # host group for etcd [etcd] etcd.example.com # host group for nodes, includes region info [nodes] master.example.com node1.example.com openshift_node_labels=”{‘region’: ‘primary’, ‘zone’: ‘east’}” node2.example.com openshift_node_labels=”{‘region’: ‘primary’, ‘zone’: ‘west’}” infra-node1.example.com openshift_node_labels=”{‘region’: ‘infra’, ‘zone’: ‘default’}” infra-node2.example.com openshift_node_labels=”{‘region’: ‘infra’, ‘zone’: ‘default’}”</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>运行</td>
</tr>
<tr>
<td>ansible-playbook ~/openshift-ansible/playbooks/byo/config.yml</td>
</tr>
<tr>
<td><a href="./media/image3.png">./media/image3.png</a></td>
</tr>
</tbody>
</table>
<h3 id="验证安装"><a href="#验证安装" class="headerlink" title="验证安装"></a>验证安装</h3><ul>
<li><p>Master上验证</p>
</li>
<li><p>确认集群状态</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>oc status</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image4.png">./media/image4.png</a></td>
</tr>
<tr>
<td>oc get nodes</td>
</tr>
<tr>
<td><a href="./media/image5.png">./media/image5.png</a></td>
</tr>
<tr>
<td>oc get all</td>
</tr>
<tr>
<td><a href="./media/image6.png">./media/image6.png</a></td>
</tr>
<tr>
<td>验证etcd</td>
</tr>
<tr>
<td>yum install etcd -y</td>
</tr>
<tr>
<td>etcdctl -C \ <a href="https://etcd.example.com:2379" target="_blank" rel="noopener">https://etcd.example.com:2379</a> \ –ca-file=/etc/origin/master/master.etcd-ca.crt \ –cert-file=/etc/origin/master/master.etcd-client.crt \ –key-file=/etc/origin/master/master.etcd-client.key cluster-health</td>
</tr>
<tr>
<td>etcdctl -C \ <a href="https://etcd.example.com:2379" target="_blank" rel="noopener">https://etcd.example.com:2379</a> \ –ca-file=/etc/origin/master/master.etcd-ca.crt \ –cert-file=/etc/origin/master/master.etcd-client.crt \ –key-file=/etc/origin/master/master.etcd-client.key member list</td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h3 id="登陆"><a href="#登陆" class="headerlink" title="登陆"></a>登陆</h3><table>
<thead>
<tr>
<th>创建用户</th>
</tr>
</thead>
<tbody>
<tr>
<td>htpasswd -b /etc/origin/master/htpasswd dev dev</td>
</tr>
<tr>
<td>给dev用户admin权限</td>
</tr>
<tr>
<td>oc login -u system:admin</td>
</tr>
<tr>
<td>oc adm policy add-cluster-role-to-user cluster-admin dev</td>
</tr>
<tr>
<td>浏览器登录</td>
</tr>
<tr>
<td><a href="https://master.example.com:8443" target="_blank" rel="noopener">https://master.example.com:8443</a></td>
</tr>
</tbody>
</table>
<h2 id="本地DNS-Server"><a href="#本地DNS-Server" class="headerlink" title="本地DNS Server"></a>本地DNS Server</h2><ul>
<li><p>在建立openshift集群时，是直接修改各节点的/etc/hosts文件，要访问Router映射出的域名，是加上静态的域名解析。当节点数量很多或者后续执行节点扩容时，都需要修改大量/etc/hosts/文件，繁琐又不智能。</p>
</li>
<li><p>这里选择在本地搭建一个DNS服务器，并选择将DNS Server部署在Master节点上。</p>
</li>
<li><p>在部署过程中已经安装好dnsmasp服务，不用安装，只需要添加配置文件即可</p>
</li>
</ul>
<h3 id="添加dnsmasp配置"><a href="#添加dnsmasp配置" class="headerlink" title="添加dnsmasp配置"></a>添加dnsmasp配置</h3><table>
<thead>
<tr>
<th>vim /etc/dnsmasq.d/local.conf</th>
</tr>
</thead>
<tbody>
<tr>
<td>address=/master.example.com/10.10.31.161 address=/<a href="http://www.ivops-rabbitmq.com/10.10.31.164" target="_blank" rel="noopener">www.ivops-rabbitmq.com/10.10.31.164</a> address=/registry-console-default.router.default.svc.cluster.local/10.10.31.164 address=/agtweb.mas.ivops/10.10.31.164 address=/agtweb2.mas.ivops/10.10.31.164</td>
</tr>
<tr>
<td><a href="./media/image7.png">./media/image7.png</a></td>
</tr>
<tr>
<td>systemctl restart dnsmasq.service</td>
</tr>
<tr>
<td>systemctl status dnsmasq.service</td>
</tr>
</tbody>
</table>
<h3 id="配置iptables"><a href="#配置iptables" class="headerlink" title="配置iptables"></a>配置iptables</h3><table>
<thead>
<tr>
<th>sed -i ‘/.*–dport 22 -j ACCEPT.*/a\-A INPUT -p tcp -m state –state NEW -m tcp –dport 53 -j ACCEPT’ /etc/sysconfig/iptables</th>
</tr>
</thead>
<tbody>
<tr>
<td>sed -i ‘/.*–dport 22 -j ACCEPT.*/a\-A INPUT -p udp -m state –state NEW -m udp –dport 53 -j ACCEPT’ /etc/sysconfig/iptables</td>
</tr>
<tr>
<td>systemctl restart iptables</td>
</tr>
<tr>
<td>systemctl status iptables</td>
</tr>
</tbody>
</table>
<h3 id="本地验证"><a href="#本地验证" class="headerlink" title="本地验证"></a>本地验证</h3><table>
<thead>
<tr>
<th><a href="./media/image8.png">./media/image8.png</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>ping master.example.com -c 2</td>
</tr>
<tr>
<td>ping agtweb.mas.ivops -c 2</td>
</tr>
<tr>
<td><a href="./media/image9.png">./media/image9.png</a></td>
</tr>
</tbody>
</table>
<h2 id="持久化存储-NFS"><a href="#持久化存储-NFS" class="headerlink" title="持久化存储-NFS"></a>持久化存储-NFS</h2><h3 id="使用NFS为后端存储"><a href="#使用NFS为后端存储" class="headerlink" title="使用NFS为后端存储"></a>使用NFS为后端存储</h3><ul>
<li>创建NFS共享目录</li>
</ul>
<table>
<thead>
<tr>
<th>mount /dev/sdc1 /mnt/nfs/</th>
</tr>
</thead>
<tbody>
<tr>
<td>yum install nfs-utils rpcbind -y</td>
</tr>
<tr>
<td>chown nfsnobody:nfsnobody /mnt/nfs/ -R</td>
</tr>
<tr>
<td>echo “/mnt/nfs *(rw,sync,all_squash)” >> /etc/exports</td>
</tr>
<tr>
<td>systemctl start rpcbind &amp;&amp; systemctl enable rpcbind</td>
</tr>
<tr>
<td>systemctl status rpcbind</td>
</tr>
<tr>
<td>exportfs -r</td>
</tr>
<tr>
<td>systemctl start nfs-server &amp;&amp; systemctl enable nfs-server</td>
</tr>
<tr>
<td>systemctl status nfs-server</td>
</tr>
<tr>
<td>showmount -e 127.0.0.1</td>
</tr>
</tbody>
</table>
<ul>
<li>测试挂载</li>
</ul>
<table>
<thead>
<tr>
<th>mkdir /mnt/nfsmount</th>
</tr>
</thead>
<tbody>
<tr>
<td>touch /mnt/nfs/test</td>
</tr>
<tr>
<td>mount 10.10.31.161:/mnt/nfs /mnt/nfsmount</td>
</tr>
<tr>
<td>ls /mnt/nfsmount/</td>
</tr>
<tr>
<td>rm -rf /mnt/nfsmount/test</td>
</tr>
<tr>
<td>df -h</td>
</tr>
<tr>
<td>umount /mnt/nfsmount/</td>
</tr>
</tbody>
</table>
<h3 id="创建Persistent-Volume"><a href="#创建Persistent-Volume" class="headerlink" title="创建Persistent Volume"></a>创建Persistent Volume</h3><ul>
<li>创建pv 的yaml文件</li>
</ul>
<table>
<thead>
<tr>
<th>vi nfs-pv.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 kind: PersistentVolume metadata: name: nfs-pv spec: capacity: storage: 1Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Retain nfs: path: /mnt/nfs server: 10.10.31.161 readOnly: false</td>
</tr>
</tbody>
</table>
<ul>
<li>创建pv卷</li>
</ul>
<table>
<thead>
<tr>
<th>oc create -f nfs-pv.yaml -n my-project</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>查看pv卷状态</li>
</ul>
<table>
<thead>
<tr>
<th>oc get pv</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h3 id="创建Persistent-Volume-Claim"><a href="#创建Persistent-Volume-Claim" class="headerlink" title="创建Persistent Volume Claim"></a>创建Persistent Volume Claim</h3><ul>
<li>创建pvc的yaml文件</li>
</ul>
<table>
<thead>
<tr>
<th>vim nfs-pvc.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nfs-pvc spec: accessModes: - ReadWriteMany volumeName: nfs-pv resources: requests: storage: 1Gi</td>
</tr>
</tbody>
</table>
<ul>
<li>创建pvc</li>
</ul>
<table>
<thead>
<tr>
<th>oc create -f nfs-pvc.yaml -n my-project</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>查看pvc状态</li>
</ul>
<table>
<thead>
<tr>
<th>oc get pvc</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h3 id="配置SELinux权限"><a href="#配置SELinux权限" class="headerlink" title="配置SELinux权限"></a>配置SELinux权限</h3><ul>
<li>开启NFS卷写入权限</li>
</ul>
<table>
<thead>
<tr>
<th>setsebool -P virt_use_nfs on</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h3 id="创建应用"><a href="#创建应用" class="headerlink" title="创建应用"></a>创建应用</h3><ul>
<li>创建pod的yaml文件</li>
</ul>
<table>
<thead>
<tr>
<th>vi nfs-nginx.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 kind: Pod metadata: name: nginx-nfs-pod labels: name: nginx-nfs-pod spec: containers: - name: nginx-nfs-pod image: fedora/nginx ports: - name: web containerPort: 80 volumeMounts: - name: nfsvol mountPath: /usr/share/nginx/html securityContext: supplementalGroups: [100003] privileged: false volumes: - name: nfsvol persistentVolumeClaim: claimName: nfs-pvc</td>
</tr>
</tbody>
</table>
<ul>
<li>创建pod</li>
</ul>
<table>
<thead>
<tr>
<th>oc create -f nfs-nginx.yaml -n my-project</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>查看pod状态</li>
</ul>
<table>
<thead>
<tr>
<th>oc get pod –n my-project</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc describe pod nginx-nfs-pod</td>
</tr>
</tbody>
</table>
<ul>
<li>在Web Console上可以看到已经挂载</li>
</ul>
<table>
<thead>
<tr>
<th><a href="./media/image10.png">./media/image10.png</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image11.png">./media/image11.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>查看底层docker状态</li>
</ul>
<table>
<thead>
<tr>
<th><a href="./media/image12.png">./media/image12.png</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>docker inspect 289c36f63273</td>
</tr>
<tr>
<td><a href="./media/image13.png">./media/image13.png</a></td>
</tr>
</tbody>
</table>
<h2 id="持久化存储-GlusterFS"><a href="#持久化存储-GlusterFS" class="headerlink" title="持久化存储-GlusterFS"></a>持久化存储-GlusterFS</h2><ol>
<li><p>使用GlusterFS为后端存储-Static</p>
<ol>
<li>部署GlusterFS集群</li>
</ol>
</li>
</ol>
<ul>
<li>环境准备</li>
</ul>
<table>
<thead>
<tr>
<th>主机名</th>
<th>IP地址</th>
<th>操作系统</th>
<th>硬件配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>gluster1</td>
<td>10.10.31.166</td>
<td>7.4 mini</td>
<td>4C2G+50G</td>
</tr>
<tr>
<td>gluster2</td>
<td>10.10.31.167</td>
<td>7.4 mini</td>
<td>4C2G+50G</td>
</tr>
<tr>
<td>gluster3</td>
<td>10.10.31.168</td>
<td>7.4 mini</td>
<td>4C2G+50G</td>
</tr>
</tbody>
</table>
<ul>
<li>准备工作</li>
</ul>
<blockquote>
<p>  配置hostname</p>
</blockquote>
<table>
<thead>
<tr>
<th>vi /etc/hosts</th>
</tr>
</thead>
<tbody>
<tr>
<td>hostnamectl set-name glsuter1</td>
</tr>
<tr>
<td>hostnamectl set-name glsuter2</td>
</tr>
<tr>
<td>hostnamectl set-name glsuter3</td>
</tr>
</tbody>
</table>
<blockquote>
<p>  关闭SELinux</p>
</blockquote>
<ul>
<li><p>开始安装，所有机器相同操作</p>
<ul>
<li>安装软件仓库</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>yum install centos-release-gluster</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>格式化数据盘</li>
</ul>
<table>
<thead>
<tr>
<th>mkfs.xfs -i size=512 /dev/sdb</th>
</tr>
</thead>
<tbody>
<tr>
<td>mkdir -p /bricks/brick1</td>
</tr>
<tr>
<td>vi /etc/fstab</td>
</tr>
<tr>
<td>/dev/sdb /bricks/brick1 xfs defaults 1 2</td>
</tr>
<tr>
<td>mount -a &amp;&amp; mount</td>
</tr>
</tbody>
</table>
<ul>
<li>安装GlusterFS</li>
</ul>
<table>
<thead>
<tr>
<th>yum –enablerepo=centos-gluster*-test install glusterfs-server</th>
</tr>
</thead>
<tbody>
<tr>
<td>systemctl start glusterd &amp;&amp; systemctl enable glusterd</td>
</tr>
</tbody>
</table>
<ul>
<li>配置trusted pool</li>
</ul>
<table>
<thead>
<tr>
<th>gluster1执行</th>
</tr>
</thead>
<tbody>
<tr>
<td>gluster peer probe gluster2</td>
</tr>
<tr>
<td>gluster peer probe gluster3</td>
</tr>
<tr>
<td>gluster peer status</td>
</tr>
<tr>
<td><a href="./media/image14.png">./media/image14.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>配置存储卷</li>
</ul>
<table>
<thead>
<tr>
<th>mkdir /bricks/brick1/gv0</th>
</tr>
</thead>
<tbody>
<tr>
<td>可以在任意一个节点执行：</td>
</tr>
<tr>
<td>gluster volume create gv0 replica 2 gluster1:/bricks/brick1/gv0 gluster2:/bricks/brick1/gv0</td>
</tr>
<tr>
<td>gluster volume start gv0</td>
</tr>
<tr>
<td>gluster volume info</td>
</tr>
</tbody>
</table>
<ul>
<li>测试挂载</li>
</ul>
<table>
<thead>
<tr>
<th>mount -t glusterfs gluster1:/gv0 /mnt</th>
</tr>
</thead>
<tbody>
<tr>
<td>GlusterFS 五种卷： Distributed：分布式卷，文件通过 hash 算法随机分布到由 bricks 组成的卷上。 Replicated: 复制式卷，类似 RAID 1，replica 数必须等于 volume 中 brick 所包含的存储服务器数，可用性高。 Striped: 条带式卷，类似 RAID 0，stripe 数必须等于 volume 中 brick 所包含的存储服务器数，文件被分成数据块，以 Round Robin 的方式存储在 bricks 中，并发粒度是数据块，大文件性能好。 Distributed Striped: 分布式的条带卷，volume中 brick 所包含的存储服务器数必须是 stripe 的倍数（>=2倍），兼顾分布式和条带式的功能。 Distributed Replicated: 分布式的复制卷，volume 中 brick 所包含的存储服务器数必须是 replica 的倍数（>=2倍），兼顾分布式和复制式的功能。</td>
</tr>
</tbody>
</table>
<h4 id="GlusterFS持久化存储"><a href="#GlusterFS持久化存储" class="headerlink" title="GlusterFS持久化存储"></a>GlusterFS持久化存储</h4><ul>
<li>在OpenShift集群所有主机上安装</li>
</ul>
<table>
<thead>
<tr>
<th>yum install glusterfs-fuse</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>OpenShift所有主机配置Hosts</li>
</ul>
<table>
<thead>
<tr>
<th>vi /etc/hosts</th>
</tr>
</thead>
<tbody>
<tr>
<td>10.10.31.166 gluster1 10.10.31.167 gluster2 10.10.31.168 gluster3</td>
</tr>
</tbody>
</table>
<ul>
<li><p>创建Gluster Endpoints</p>
<ul>
<li>先创建Service</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>vi gluster-service.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 kind: Service metadata: name: gluster-cluster spec: ports: - port: 1</td>
</tr>
<tr>
<td>oc create -f gluster-service.yaml -n s2i-project</td>
</tr>
<tr>
<td>oc get svc</td>
</tr>
</tbody>
</table>
<ul>
<li>创建Endpoint</li>
</ul>
<table>
<thead>
<tr>
<th>vi gluster-endpoints.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 kind: Endpoints metadata: name: gluster-cluster subsets: - addresses: - ip: 10.10.31.166 ports: - port: 1 protocol: TCP - addresses: - ip: 10.10.31.167 ports: - port: 1 protocol: TCP - addresses: - ip: 10.10.31.168 ports: - port: 1 protocol: TCP</td>
</tr>
<tr>
<td>oc create -f gluster-endpoints.yaml -n s2i-project</td>
</tr>
<tr>
<td>oc get endpoint</td>
</tr>
</tbody>
</table>
<h4 id="创建Persistent-Volume-1"><a href="#创建Persistent-Volume-1" class="headerlink" title="创建Persistent Volume"></a>创建Persistent Volume</h4><table>
<thead>
<tr>
<th>vi gluster-pv.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 kind: PersistentVolume metadata: name: gluster-pv spec: capacity: storage: 1Gi accessModes: - ReadWriteMany glusterfs: endpoints: gluster-cluster path: /gv0 readOnly: false persistentVolumeReclaimPolicy: Retain</td>
</tr>
<tr>
<td>oc create -f gluster-pv.yaml -n s2i-project</td>
</tr>
<tr>
<td>oc get pv</td>
</tr>
</tbody>
</table>
<h4 id="创建Persistent-Volume-Claim-1"><a href="#创建Persistent-Volume-Claim-1" class="headerlink" title="创建Persistent Volume Claim"></a>创建Persistent Volume Claim</h4><table>
<thead>
<tr>
<th>vi gluster-claim.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 kind: PersistentVolumeClaim metadata: name: gluster-claim spec: accessModes: - ReadWriteMany resources: requests: storage: 1Gi</td>
</tr>
<tr>
<td>oc create -f gluster-claim.yaml -n s2i-project</td>
</tr>
<tr>
<td>oc get pvc</td>
</tr>
</tbody>
</table>
<h4 id="配置SELinux权限-1"><a href="#配置SELinux权限-1" class="headerlink" title="配置SELinux权限"></a>配置SELinux权限</h4><table>
<thead>
<tr>
<th>setsebool -P virt_sandbox_use_fusefs on</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h4 id="创建应用-1"><a href="#创建应用-1" class="headerlink" title="创建应用"></a>创建应用</h4><ul>
<li>由于使用的nginx镜像需要特殊权限运行，配置SCC</li>
</ul>
<table>
<thead>
<tr>
<th>oc adm policy add-scc-to-user privileged myuser</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>创建Pod</li>
</ul>
<table>
<thead>
<tr>
<th>vim gluster-pod1.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 kind: Pod metadata: name: gluster-pod1 labels: name: gluster-pod1 spec: containers: - name: gluster-pod1 image: nginx ports: - name: web containerPort: 80 securityContext: privileged: true volumeMounts: - name: gluster-vol1 mountPath: /usr/share/nginx/html readOnly: false volumes: - name: gluster-vol1 persistentVolumeClaim: claimName: gluster-claim</td>
</tr>
<tr>
<td>oc create -f gluster-pod1.yaml -n s2i-project</td>
</tr>
<tr>
<td>oc get pod</td>
</tr>
<tr>
<td><a href="./media/image15.png">./media/image15.png</a></td>
</tr>
<tr>
<td><a href="./media/image16.png">./media/image16.png</a></td>
</tr>
</tbody>
</table>
<ol>
<li><p>使用GlusterFS为后端存储-Dynamic</p>
<ol>
<li>新部署GlusterFS，使用Heketi管理</li>
</ol>
</li>
</ol>
<ul>
<li>环境准备</li>
</ul>
<table>
<thead>
<tr>
<th>主机名</th>
<th>IP地址</th>
<th>操作系统</th>
<th>硬件配置</th>
</tr>
</thead>
<tbody>
<tr>
<td>gluster1</td>
<td>10.10.31.166</td>
<td>7.4 mini</td>
<td>4C2G+50G</td>
</tr>
<tr>
<td>gluster2</td>
<td>10.10.31.167</td>
<td>7.4 mini</td>
<td>4C2G+50G</td>
</tr>
<tr>
<td>gluster3</td>
<td>10.10.31.168</td>
<td>7.4 mini</td>
<td>4C2G+50G</td>
</tr>
</tbody>
</table>
<ul>
<li>准备工作</li>
</ul>
<blockquote>
<p>  配置hostname</p>
</blockquote>
<table>
<thead>
<tr>
<th>vi /etc/hosts</th>
</tr>
</thead>
<tbody>
<tr>
<td>10.10.31.166 gluster1 10.10.31.167 gluster2 10.10.31.168 gluster3</td>
</tr>
<tr>
<td>hostnamectl set-hostname glsuter1</td>
</tr>
<tr>
<td>hostnamectl set-hostname glsuter2</td>
</tr>
<tr>
<td>hostnamectl set-hostname glsuter3</td>
</tr>
</tbody>
</table>
<blockquote>
<p>  关闭SELinux</p>
</blockquote>
<ul>
<li><p>开始安装，所有机器相同操作</p>
<ul>
<li>安装软件仓库</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>yum install centos-release-gluster -y</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>安装GlusterFS</li>
</ul>
<table>
<thead>
<tr>
<th>yum install glusterfs-server -y</th>
</tr>
</thead>
<tbody>
<tr>
<td>systemctl start glusterd &amp;&amp; systemctl enable glusterd</td>
</tr>
<tr>
<td>systemctl status glusterd</td>
</tr>
</tbody>
</table>
<h4 id="安装Heketi"><a href="#安装Heketi" class="headerlink" title="安装Heketi"></a>安装Heketi</h4><ul>
<li><p>Heketi用于管理GlusterFS的REST API</p>
</li>
<li><p>在GlusterFS其中一台虚拟机上安装，这里选择gluster3</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>yum install heketi heketi-client -y</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>Heketi使用SSH来配置GlusterFS的所有节点。创建SSH密钥对，将公钥拷贝到所有3个节点上</li>
</ul>
<table>
<thead>
<tr>
<th>ssh-keygen -f /etc/heketi/heketi_key -t rsa -N ‘’</th>
</tr>
</thead>
<tbody>
<tr>
<td>ssh-copy-id -i /etc/heketi/heketi_key.pub root\@gluster1 ssh-copy-id -i /etc/heketi/heketi_key.pub root\@gluster2 ssh-copy-id -i /etc/heketi/heketi_key.pub root\@gluster3</td>
</tr>
<tr>
<td>chown heketi:heketi /etc/heketi/heketi_key*</td>
</tr>
</tbody>
</table>
<ul>
<li>配置heketi使用SSH</li>
</ul>
<table>
<thead>
<tr>
<th>vim /etc/heketi/heketi.json</th>
</tr>
</thead>
<tbody>
<tr>
<td>“executor”: “ssh”, “_sshexec_comment”: “SSH username and private key file information”, “sshexec”: { “keyfile”: “/etc/heketi/heketi_key”, “user”: “root”, “port”: “22”, “fstab”: “/etc/fstab” },</td>
</tr>
<tr>
<td><a href="./media/image17.png">./media/image17.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>启动服务</li>
</ul>
<table>
<thead>
<tr>
<th>systemctl restart heketi</th>
</tr>
</thead>
<tbody>
<tr>
<td>systemctl enable heketi</td>
</tr>
<tr>
<td>systemctl status heketi</td>
</tr>
</tbody>
</table>
<ul>
<li>测试服务状态</li>
</ul>
<table>
<thead>
<tr>
<th>curl <a href="http://gluster3:8080/hello" target="_blank" rel="noopener">http://gluster3:8080/hello</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image18.png">./media/image18.png</a></td>
</tr>
</tbody>
</table>
<h4 id="配置Topology"><a href="#配置Topology" class="headerlink" title="配置Topology"></a>配置Topology</h4><ul>
<li>配置环境变量</li>
</ul>
<table>
<thead>
<tr>
<th>export HEKETI_CLI_SERVER=<a href="http://gluster3:8080" target="_blank" rel="noopener">http://gluster3:8080</a></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>准备json文件</li>
</ul>
<table>
<thead>
<tr>
<th>vim topology.json</th>
</tr>
</thead>
<tbody>
<tr>
<td>{ “clusters”: [ { “nodes”: [ { “node”: { “hostnames”: { “manage”: [ “gluster1” ], “storage”: [ “10.10.31.166” ] }, “zone”: 1 }, “devices”: [ “/dev/sdb” ] }, { “node”: { “hostnames”: { “manage”: [ “gluster2” ], “storage”: [ “10.10.31.167” ] }, “zone”: 1 }, “devices”: [ “/dev/sdb” ] }, { “node”: { “hostnames”: { “manage”: [ “gluster3” ], “storage”: [ “10.10.31.168” ] }, “zone”: 1 }, “devices”: [ “/dev/sdb” ] } ] } ] }</td>
</tr>
<tr>
<td>该文件格式，是告诉heketi要创建一个3节点的集群，其中每个节点包含的配置有FQDN，IP地址以及至少一个将用作GlusterFS块的备用块设备。</td>
</tr>
</tbody>
</table>
<ul>
<li>运行</li>
</ul>
<table>
<thead>
<tr>
<th>heketi-cli topology load –json=topology.json</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>验证</li>
</ul>
<table>
<thead>
<tr>
<th>gluster peer status</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>创建一个数据卷</li>
</ul>
<table>
<thead>
<tr>
<th>heketi-cli volume create –size=20</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image19.png">./media/image19.png</a></td>
</tr>
<tr>
<td>gluster volume info</td>
</tr>
<tr>
<td><a href="./media/image20.png">./media/image20.png</a></td>
</tr>
</tbody>
</table>
<h3 id="将Gluster与OpenShift集成"><a href="#将Gluster与OpenShift集成" class="headerlink" title="将Gluster与OpenShift集成"></a>将Gluster与OpenShift集成</h3><p>集成OpenShift，需要一个动态的Kubernetes Storage Provisioner和一个StorageClass。<br>Provisioner在OpenShift中开箱即用。 实际上关键的是如何将存储挂载到容器上。<br>StorageClass是OpenShift中的用户可以用来实现的PersistentVolumeClaims的实体，它反过来能够触发一个Provisioner实现实际的配置，并将结果表示为Kubernetes<br>PersistentVolume（PV）。</p>
<h4 id="先创建一个测试项目，在OpenShift-Master上执行"><a href="#先创建一个测试项目，在OpenShift-Master上执行" class="headerlink" title="先创建一个测试项目，在OpenShift Master上执行"></a>先创建一个测试项目，在OpenShift Master上执行</h4><table>
<thead>
<tr>
<th>oc new-project gluster-storage</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h4 id="创建StorageClass"><a href="#创建StorageClass" class="headerlink" title="创建StorageClass"></a>创建StorageClass</h4><table>
<thead>
<tr>
<th>vi glusterfs-storageclass1.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: gluster-dyn annotations: storageclass.kubernetes.io/is-default-class: “true” provisioner: kubernetes.io/glusterfs parameters: resturl: “<a href="http://gluster3:8080&quot;" target="_blank" rel="noopener">http://gluster3:8080&quot;</a> restauthenabled: “false”</td>
</tr>
<tr>
<td>oc create -f glusterfs-storageclass1.yaml</td>
</tr>
<tr>
<td>oc get sc</td>
</tr>
<tr>
<td><a href="./media/image21.png">./media/image21.png</a></td>
</tr>
<tr>
<td>我们的provisioner是kubernetes.io/glusterfs，将它指向我们的heketi实例。 我们将类命名为“gluster-dyn”， 同时使其成为所有没有显示指定StorageClass的PersistentVolumeClaim的默认StorageClass。</td>
</tr>
</tbody>
</table>
<h4 id="创建Persistent-Volume-Claim-2"><a href="#创建Persistent-Volume-Claim-2" class="headerlink" title="创建Persistent Volume Claim"></a>创建Persistent Volume Claim</h4><table>
<thead>
<tr>
<th>#新建这个PVC只为测试</th>
</tr>
</thead>
<tbody>
<tr>
<td>vi glusterfs-pvc-storageclass.yaml</td>
</tr>
<tr>
<td>apiVersion: v1 kind: PersistentVolumeClaim metadata: name: gluster-dyn-pvc spec: accessModes: - ReadWriteMany resources: requests: storage: 10Gi storageClassName: gluster-dyn</td>
</tr>
<tr>
<td>oc create -f glusterfs-pvc-storageclass.yaml</td>
</tr>
<tr>
<td>oc get pvc</td>
</tr>
<tr>
<td><a href="./media/image22.png">./media/image22.png</a></td>
</tr>
</tbody>
</table>
<h4 id="验证GlusterFS-Volume"><a href="#验证GlusterFS-Volume" class="headerlink" title="验证GlusterFS Volume"></a>验证GlusterFS Volume</h4><p>回到GlusterFS集群中，查看volume状态</p>
<table>
<thead>
<tr>
<th>gluster volume info</th>
</tr>
</thead>
<tbody>
<tr>
<td>可以看到当前glusterfs里存在两个Volume， 第一个Volume是上面用heketi-cli volume create创建的测试Volume， 第二个Volume是StorageClass通过PVC创建的Volume</td>
</tr>
<tr>
<td><a href="./media/image23.png">./media/image23.png</a></td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td><a href="./media/image24.png">./media/image24.png</a></td>
</tr>
</tbody>
</table>
<h4 id="Web-Console"><a href="#Web-Console" class="headerlink" title="Web Console"></a>Web Console</h4><table>
<thead>
<tr>
<th><a href="./media/image25.png">./media/image25.png</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image26.png">./media/image26.png</a></td>
</tr>
</tbody>
</table>
<h3 id="创建应用-2"><a href="#创建应用-2" class="headerlink" title="创建应用"></a>创建应用</h3><ul>
<li>创建pod的yaml文件</li>
</ul>
<table>
<thead>
<tr>
<th>vi nginx-pod-gluster.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 kind: Pod metadata: name: gluster-pod1-gluster labels: name: gluster-pod1-gluster spec: containers: - name: gluster-pod1-gluster image: nginx ports: - name: web containerPort: 80 securityContext: privileged: true volumeMounts: - name: gluster-vol1-gluster mountPath: /usr/share/nginx/html volumes: - name: gluster-vol1-gluster persistentVolumeClaim: claimName: gluster-dyn-pvc</td>
</tr>
<tr>
<td>oc create -f nginx-pod-gluster.yaml</td>
</tr>
<tr>
<td>oc get pod –o wide</td>
</tr>
<tr>
<td><a href="./media/image27.png">./media/image27.png</a></td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td><a href="./media/image28.png">./media/image28.png</a></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>测试应用</li>
</ul>
<table>
<thead>
<tr>
<th><a href="./media/image29.png">./media/image29.png</a></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h2 id="深入了解Pod"><a href="#深入了解Pod" class="headerlink" title="深入了解Pod"></a>深入了解Pod</h2><h3 id="Pod的定义"><a href="#Pod的定义" class="headerlink" title="Pod的定义"></a>Pod的定义</h3><p>Pod是Kubernetes下的概念，pod的容器的载体，所有容器都是在pod中被管理，一个或多个容器放在pod里作为一个单元方便管理。</p>
<table>
<thead>
<tr>
<th>下面是一个完整的yaml格式定义的文件,注意格式，子集包含关系，不要有tab，要用空格。</th>
</tr>
</thead>
<tbody>
<tr>
<td>apiVersion: v1 //版本 kind: pod //类型，pod metadata: //元数据 name: String //元数据，pod的名字 namespace: String //元数据，pod的命名空间 labels: //元数据，标签列表 - name: String //元数据，标签的名字 annotations: //元数据,自定义注解列表 - name: String //元数据,自定义注解名字 spec: //pod中容器的详细定义 containers: //pod中的容器列表，可以有多个容器 - name: String image: String //容器中的镜像 imagesPullPolicy: [Always\</td>
<td>Never\</td>
<td>IfNotPresent]//获取镜像的策略 command: [String] //容器的启动命令列表（不配置的话使用镜像内部的命令） args: [String] //启动参数列表 workingDir: String //容器的工作目录 volumeMounts: //挂载到到容器内部的存储卷设置 - name: String mountPath: String readOnly: boolean ports: //容器需要暴露的端口号列表 - name: String containerPort: int //容器要暴露的端口 hostPort: int //容器所在主机监听的端口（容器暴露端口映射到宿主机的端口） protocol: String env: //容器运行前要设置的环境列表 - name: String value: String resources: //资源限制 limits: cpu: Srting memory: String requeste: cpu: String memory: String livenessProbe: //pod内容器健康检查的设置 exec: command: [String] httpGet: //通过httpget检查健康 path: String port: number host: String scheme: Srtring httpHeaders: - name: Stirng value: String tcpSocket: //通过tcpSocket检查健康 port: number initialDelaySeconds: 0//首次检查时间 timeoutSeconds: 0 //检查超时时间 periodSeconds: 0 //检查间隔时间 successThreshold: 0 failureThreshold: 0 securityContext: //安全配置 privileged: falae restartPolicy: [Always\</td>
<td>Never\</td>
<td>OnFailure]//重启策略 nodeSelector: object //节点选择 imagePullSecrets: - name: String hostNetwork: false //是否使用主机网络模式，默认否 volumes: //在该pod上定义共享存储卷 - name: String meptyDir: {} hostPath: path: string secret: //类型为secret的存储卷 secretName: String item: - key: String path: String configMap: //类型为configMap的存储卷 name: String items: - key: String path: String</td>
</tr>
</tbody>
</table>
<h3 id="Pod的配置管理"><a href="#Pod的配置管理" class="headerlink" title="Pod的配置管理"></a>Pod的配置管理</h3><ul>
<li><p>应用部署的最佳实践，就是将应用所需的配置信息与程序进行分离。</p>
</li>
<li><p>OpenShift提供一种集群配置管理方案：ConfigMap，就是将一些环境变量或者配置文件定义为configmap，放在OpenShift中，可以让其他pod调用。</p>
</li>
<li><p>ConfigMap有以下典型用法</p>
<ul>
<li><p>生成为容器内的环境变量</p>
</li>
<li><p>设置容器启动命令的启动参数</p>
</li>
<li><p>以volume的形式挂载为容器内部的文件或目录</p>
</li>
</ul>
</li>
</ul>
<p>使用示例：</p>
<table>
<thead>
<tr>
<th>定义一个ConfigMap配置文件</th>
</tr>
</thead>
<tbody>
<tr>
<td>vi cm-appvars.yaml</td>
</tr>
<tr>
<td>apiVersion: v1 kind: ConfigMap metadata: name: cm-appvars data: apploglevel: info appdatadir: /var/date</td>
</tr>
<tr>
<td>oc create -f cm-appvars.yaml</td>
</tr>
<tr>
<td></td>
</tr>
<tr>
<td>使用ConfigMap</td>
</tr>
<tr>
<td>apiVersion: v1 kind: Pod metadata: name: cm-test-pod spec: containers: - name: cm-test image: busybux env: - name: APPLOGLEVEL vlaueFrom: configMapKeyRef: name: cm-appvars //要和之前创建的ConfigMap的name对应 key: apploglevel - name: APPDATADIR vlaueFrom: configMapKeyRef: name: cm-appvars //要和之前创建的ConfigMap的name对应 key: appdatadir</td>
</tr>
</tbody>
</table>
<h3 id="Pod生命周期和重启策略"><a href="#Pod生命周期和重启策略" class="headerlink" title="Pod生命周期和重启策略"></a>Pod生命周期和重启策略</h3><ul>
<li>Pod一共有四种状态</li>
</ul>
<table>
<thead>
<tr>
<th>状态值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pending</td>
<td>APIserver已经创建该server,但pod内有一个或多个容器的镜像还未创建，可能在下载中。</td>
</tr>
<tr>
<td>Running</td>
<td>APIserver已经创建该server,但pod内有一个或多个容器的镜像还未创建，可能在下载中。</td>
</tr>
<tr>
<td>Failed</td>
<td>Pod内所有容器都已退出，其中至少有一个容器退出失败</td>
</tr>
<tr>
<td>Unknown</td>
<td>由于某种原因无法获取Pod的状态比如网络不通。</td>
</tr>
</tbody>
</table>
<ul>
<li>Pod的重启策略应用于Pod内的所有容器，由Pod所在Node节点上的Kubelet进行判断和重启操作。重启策略有以下三种:</li>
</ul>
<table>
<thead>
<tr>
<th>重启策略</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Always</td>
<td>容器失效时，即重启</td>
</tr>
<tr>
<td>OnFailure</td>
<td>容器终止运行，且退出码不为0 时重启</td>
</tr>
<tr>
<td>Never</td>
<td>永不重启</td>
</tr>
</tbody>
</table>
<h3 id="Pod调度机制"><a href="#Pod调度机制" class="headerlink" title="Pod调度机制"></a>Pod调度机制</h3><p>在OpenShift系统中，pod在大部分场景下都只是容器的载体而已，通常需要通过Deployment,DaemonSet,Job等对象来完成Pod的调度与自动控制功能。</p>
<ul>
<li><p>RC,Deployment: 全自动调度</p>
<ul>
<li>RC的主要功能之一就是自动部署一个容器应用的多份副本，以及持续监控，保持集群内有一定数量的副本数量（配置文件指定了副本数量）</li>
</ul>
</li>
<li><p>DaemonSet: 特定场景调度</p>
<ul>
<li>DaemonSet,用于管理在集群中每个Node上只运行一份Pod的副本实例，比如在每节点上都运行有且只有一个fluentd</li>
</ul>
</li>
</ul>
<h3 id="Pod扩容和缩容"><a href="#Pod扩容和缩容" class="headerlink" title="Pod扩容和缩容"></a>Pod扩容和缩容</h3><ul>
<li><p>通过scale来完成扩容或缩容</p>
</li>
<li><p>动态扩容缩容（HPA）</p>
</li>
</ul>
<h2 id="深入了解Service"><a href="#深入了解Service" class="headerlink" title="深入了解Service"></a>深入了解Service</h2><p>由于Pod的IP会变化，提供某些功能的POD如果IP发生变化，会导致其他Pod无法发现这些功能，因此<br>引入了Service的功能。</p>
<h3 id="Service的定义"><a href="#Service的定义" class="headerlink" title="Service的定义"></a>Service的定义</h3><table>
<thead>
<tr>
<th>{ “kind”: “Service”, “apiVersion”: “v1”, “metadata”: { “name”: “my-service” }, “spec”: { “selector”: { “app”: “MyApp” }, “ports”: [ “protocol”: “TCP”, “port”: 80, “targetPort”: 9376 } ] } }</th>
</tr>
</thead>
<tbody>
<tr>
<td>该Service 对应的Pod集合：带有label app=Myapp，对外暴露端口9376</td>
</tr>
<tr>
<td>Service 能将任意的流入Port 重定向到targetPort,默认情况下，targetPort和Port为相同值，不同的Pod 可以对应不同的端口号（例如，在你应用的下一个版本中会使用不同的端口号，但是并不应用之前版本的使用）</td>
</tr>
<tr>
<td>Service 支持UDP和TCP，默认是TCP</td>
</tr>
</tbody>
</table>
<h3 id="Service虚拟IP和服务代理"><a href="#Service虚拟IP和服务代理" class="headerlink" title="Service虚拟IP和服务代理"></a>Service虚拟IP和服务代理</h3><ul>
<li><p>K8s集群内每个节点都会运行kube-proxy，负责实现服务的虚拟机IP（不是externalName）</p>
</li>
<li><p>Kube-proxy监控k8s<br>master节点来发现Service、Endpointd的增加和删除，对于Service，在本地打开一个随机端口作为代理端口，任何访问改代理端口的连接都会被指向Service对象的Pod集合，最终指向哪个Pod取决于Service的SessionAffinity，最后，他会配置iptables，捕获流向Service 的Cluster<br>IP 和Port的连接，并重定向到这个代理端口。</p>
</li>
</ul>
<h2 id="网络连通性"><a href="#网络连通性" class="headerlink" title="网络连通性"></a>网络连通性</h2><h3 id="网络实现"><a href="#网络实现" class="headerlink" title="网络实现"></a>网络实现</h3><ul>
<li>查看各节点分配到的子网，每个节点默认都会被分配到一个子网，在计算节点上运行的Pod的ip将来源于此网段</li>
</ul>
<table>
<thead>
<tr>
<th>oc get hostsubnets</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image30.png">./media/image30.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>通过配置文件可以修改默认子网段</li>
</ul>
<table>
<thead>
<tr>
<th>vim /etc/origin/master/master-config.yaml</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image31.png">./media/image31.png</a></td>
</tr>
</tbody>
</table>
<h2 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h2><ul>
<li><p>OpenShift Web Console 不支持 https 安全验证，在Deploy Image是使用Image<br>Name部署是提示证书验证失败</p>
<ul>
<li>第一种方式：用命令行加参数</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>oc new-app –insecure-registry dtr.ivops.cn:5443/ivops/nginx-alpine:v1.1.x –name=nginx-alpine-test</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>第二种方式：使用Image Stream方式</li>
</ul>
<table>
<thead>
<tr>
<th>vi ivops-mariadb.json</th>
</tr>
</thead>
<tbody>
<tr>
<td>{ “kind”: “ImageStream”, “apiVersion”: “v1”, “metadata”: { “name”: “ivops-mariadb”, “creationTimestamp”: null }, “spec”: { “dockerImageRepository”: “dtr.ivops.cn:5443/ivops/mariadb”, “tags”: [ { “name”: “v1.1.x”, “annotations”: null, “from”: { “kind”: “DockerImage”, “name”: “dtr.ivops.cn:5443/ivops/mariadb:v1.1.x” }, “generation”: 1, “importPolicy”: { “insecure”: true } } ] } }</td>
</tr>
<tr>
<td>oc create -f ivops-mariadb.json -n s2i-project</td>
</tr>
<tr>
<td><a href="./media/image32.png">./media/image32.png</a></td>
</tr>
<tr>
<td>创建template，为以后快捷创建</td>
</tr>
<tr>
<td>oc export dc,svc,route -o json –as-template=ivops-mariadb > ivops-mariadb.template</td>
</tr>
<tr>
<td>把 “image”: “dtr.ivops.cn:5443/ivops/mariadb”, 改为 “image”: “” 这样做的目的是，根据 template 创建应用后，自动发布，不用再手工点击 Deploy。</td>
</tr>
<tr>
<td>oc create -f ivops-mariadb.template -n openshift</td>
</tr>
</tbody>
</table>
<ul>
<li>Deployer Image镜像需要以Root启动，导致启动失败</li>
</ul>
<table>
<thead>
<tr>
<th>oadm policy add-scc-to-user anyuid -z default</th>
</tr>
</thead>
<tbody>
<tr>
<td>参考链接：<a href="https://blog.openshift.com/getting-any-docker-image-running-in-your-own-openshift-cluster/" target="_blank" rel="noopener">https://blog.openshift.com/getting-any-docker-image-running-in-your-own-openshift-cluster/</a></td>
</tr>
</tbody>
</table>
<ul>
<li><p>若没有DNS Server解析Route的地址，需配置本地Host</p>
<ul>
<li>手动添加解析将“Route URL”指向Router服务所在的IP地址</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th><a href="./media/image33.png">./media/image33.png</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image34.png">./media/image34.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li><p>创建PVC的容量小于等于PV的容量</p>
</li>
<li><p>Registry-console控制台用户登陆，配置权限给用户dev</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>oc adm policy add-cluster-role-to-user cluster-admin dev</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image35.png">./media/image35.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>修改资源预留配额</li>
</ul>
<table>
<thead>
<tr>
<th><a href="./media/image36.jpeg">./media/image36.jpeg</a></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p>~   ../../../../Library/Containers/com.tencent.xinWeChat/Data/Library/Application%20Support/com.tencent.xinWeChat/2.0b4.0.9/28af29c3fcfa1b71d38c69c1e52a17f1/Message/MessageTemp/9e20f478899dc29eb19741386f9343c8/Image/931514879804_.pic_hd.jp</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fearchen.github.io/2018/04/25/OpenShift-架构了解与实践/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chen Fei">
      <meta itemprop="description" content="把我的过程记录下来，以免以后忘了">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fearchen's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/04/25/OpenShift-架构了解与实践/" itemprop="url">
                  OpenShift架构了解与实践
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-04-25 09:51:07 / 修改时间：10:04:25" itemprop="dateCreated datePublished" datetime="2018-04-25T09:51:07+08:00">2018-04-25</time>
            

            
              

              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/OpenShift/" itemprop="url" rel="index"><span itemprop="name">OpenShift</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>=======================</p>
<h1 id="OpenShift-Origin-与OPENSHIFT-CONTAINER-PLATFORM对比"><a href="#OpenShift-Origin-与OPENSHIFT-CONTAINER-PLATFORM对比" class="headerlink" title=" OpenShift Origin 与OPENSHIFT CONTAINER PLATFORM对比"></a> OpenShift Origin 与OPENSHIFT CONTAINER PLATFORM对比</h1><table>
<thead>
<tr>
<th>参考链接：<a href="http://t.cn/RlPRzS5" target="_blank" rel="noopener">http://t.cn/RlPRzS5</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image1.png">./media/image1.png</a></td>
</tr>
</tbody>
</table>
<h1 id="启动OpenShift-Origin"><a href="#启动OpenShift-Origin" class="headerlink" title=" 启动OpenShift Origin"></a> 启动OpenShift Origin</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ul>
<li>虚拟机配置如下：</li>
</ul>
<table>
<thead>
<tr>
<th>CPU</th>
<th>内存</th>
<th>磁盘</th>
<th>系统</th>
<th>安装模式</th>
</tr>
</thead>
<tbody>
<tr>
<td>1核</td>
<td>2GB</td>
<td>20GB</td>
<td>Centos7.2</td>
<td>Minimal</td>
</tr>
</tbody>
</table>
<ul>
<li>操作系统配置：</li>
</ul>
<table>
<thead>
<tr>
<th>#配置固定IP</th>
</tr>
</thead>
<tbody>
<tr>
<td>#试验环境关闭防火墙</td>
</tr>
<tr>
<td>#配置主机名</td>
</tr>
<tr>
<td>hostnamectl set-hostname master.example.com</td>
</tr>
<tr>
<td>#修改hosts</td>
</tr>
<tr>
<td>Vi /etc/hosts</td>
</tr>
<tr>
<td>#添加主机名记录</td>
</tr>
<tr>
<td>172.16.142.132 master.example.com</td>
</tr>
</tbody>
</table>
<h2 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h2><table>
<thead>
<tr>
<th>#Yum安装</th>
</tr>
</thead>
<tbody>
<tr>
<td>yum install docker -y</td>
</tr>
<tr>
<td>#配置启动服务</td>
</tr>
<tr>
<td>systemctl enable docker &amp;&amp; systemctl start docker</td>
</tr>
<tr>
<td>#修改docker镜像站</td>
</tr>
<tr>
<td>vim /etc/sysconfig/docker</td>
</tr>
<tr>
<td>OPTIONS=’–selinux-enabled –log-driver=journald –signature-verification=false –registry-mirror=<a href="https://docker.mirrors.ustc.edu.cn’" target="_blank" rel="noopener">https://docker.mirrors.ustc.edu.cn’</a></td>
</tr>
<tr>
<td>systemctl restart docker</td>
</tr>
</tbody>
</table>
<h2 id="下载OpenShift-Origin安装包"><a href="#下载OpenShift-Origin安装包" class="headerlink" title="下载OpenShift Origin安装包"></a>下载OpenShift Origin安装包</h2><table>
<thead>
<tr>
<th>#书中使用版本为1.3.0，目前最新为3.6，可在github release中下载，URL： <a href="https://github.com/OpenShift/origin/releases" target="_blank" rel="noopener">https://github.com/OpenShift/origin/releases</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>cd /opt</td>
</tr>
<tr>
<td>wget <a href="https://github.com/OpenShift/origin/releases/download/v1.3.0/OpenShift-origin-server-v1.3.0-3ab7af3d097b57f933eccef684a714f2368804e7-linux-64bit.tar.gz" target="_blank" rel="noopener">https://github.com/OpenShift/origin/releases/download/v1.3.0/OpenShift-origin-server-v1.3.0-3ab7af3d097b57f933eccef684a714f2368804e7-linux-64bit.tar.gz</a></td>
</tr>
<tr>
<td>#解压</td>
</tr>
<tr>
<td>tar zxvf <a href="https://github.com/OpenShift/origin/releases/download/v1.3.0/OpenShift-origin-server-v1.3.0-3ab7af3d097b57f933eccef684a714f2368804e7-linux-64bit.tar.gz" target="_blank" rel="noopener">https://github.com/OpenShift/origin/releases/download/v1.3.0/OpenShift-origin-server-v1.3.0-3ab7af3d097b57f933eccef684a714f2368804e7-linux-64bit.tar.gz</a></td>
</tr>
<tr>
<td>#建软连接</td>
</tr>
<tr>
<td>ln -s OpenShift-origin-server-v1.3.0-3ab7af3d097b57f933eccef684a714f2368804e7-linux-64bit /opt/OpenShift</td>
</tr>
<tr>
<td><a href="./media/image2.png">./media/image2.png</a></td>
</tr>
<tr>
<td>#添加环境变量</td>
</tr>
<tr>
<td>vim /etc/profile PATH=\$PATH:/opt/OpenShift/</td>
</tr>
<tr>
<td>source /etc/profile</td>
</tr>
</tbody>
</table>
<h2 id="验证启动"><a href="#验证启动" class="headerlink" title="验证启动 "></a>验证启动 </h2><table>
<thead>
<tr>
<th>#查看版本</th>
</tr>
</thead>
<tbody>
<tr>
<td>openshift version</td>
</tr>
<tr>
<td><a href="./media/image3.png">./media/image3.png</a></td>
</tr>
<tr>
<td>#启动</td>
</tr>
<tr>
<td>cd /opt/openshift</td>
</tr>
<tr>
<td>openshift start &amp;</td>
</tr>
<tr>
<td>#注： #“OpenShift start”命令启动是为了可以在控制台看到日志输出； #正式环境官方推荐使用“oc cluster up”方式启动。</td>
</tr>
<tr>
<td>#当日志停止输出表示启动完成</td>
</tr>
<tr>
<td>#浏览器访问<a href="https://master.example.com:8443" target="_blank" rel="noopener">https://master.example.com:8443</a></td>
</tr>
<tr>
<td><a href="./media/image4.png">./media/image4.png</a></td>
</tr>
<tr>
<td>默认账号密码dev:dev</td>
</tr>
</tbody>
</table>
<h1 id="简单使用OpenShift"><a href="#简单使用OpenShift" class="headerlink" title=" 简单使用OpenShift"></a> 简单使用OpenShift</h1><h2 id="运行容器应用"><a href="#运行容器应用" class="headerlink" title="运行容器应用"></a>运行容器应用</h2><ul>
<li>创建项目</li>
</ul>
<table>
<thead>
<tr>
<th>#登陆后的初始页，点击“New Project”</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image5.png">./media/image5.png</a></td>
</tr>
<tr>
<td>#填入相应信息</td>
</tr>
<tr>
<td><a href="./media/image6.png">./media/image6.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>部署Docker镜像</li>
</ul>
<table>
<thead>
<tr>
<th>#通过“Deploy Image”部署</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image7.png">./media/image7.png</a></td>
</tr>
<tr>
<td><a href="./media/image8.png">./media/image8.png</a></td>
</tr>
<tr>
<td><a href="./media/image9.png">./media/image9.png</a></td>
</tr>
<tr>
<td>#启动成功</td>
</tr>
<tr>
<td><a href="./media/image10.png">./media/image10.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>访问容器应用</li>
</ul>
<table>
<thead>
<tr>
<th>#确认应用IP</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image11.png">./media/image11.png</a></td>
</tr>
<tr>
<td>#终端访问测试</td>
</tr>
<tr>
<td>curl 172.30.248.254:8080</td>
</tr>
<tr>
<td><a href="./media/image12.png">./media/image12.png</a></td>
</tr>
</tbody>
</table>
<h2 id="使用命令行工具"><a href="#使用命令行工具" class="headerlink" title="使用命令行工具"></a>使用命令行工具</h2><table>
<thead>
<tr>
<th>#命令行登陆</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc login -u dev <a href="https://172.16.142.132:8443" target="_blank" rel="noopener">https://172.16.142.132:8443</a></td>
</tr>
<tr>
<td><a href="./media/image13.png">./media/image13.png</a></td>
</tr>
<tr>
<td>#创建project</td>
</tr>
<tr>
<td>oc new-project hello-world-oc</td>
</tr>
<tr>
<td><a href="./media/image14.png">./media/image14.png</a></td>
</tr>
<tr>
<td>#部署应用</td>
</tr>
<tr>
<td>oc new-app OpenShift/hello-world</td>
</tr>
<tr>
<td>#查看状态</td>
</tr>
<tr>
<td>oc get pod</td>
</tr>
</tbody>
</table>
<h2 id="集群管理员登陆"><a href="#集群管理员登陆" class="headerlink" title="集群管理员登陆"></a>集群管理员登陆</h2><ul>
<li>配置证书</li>
</ul>
<table>
<thead>
<tr>
<th>默认集群管理员是system:admin，没有密码，只能通过证书登陆</th>
</tr>
</thead>
<tbody>
<tr>
<td>mkdir -p ~/.kube</td>
</tr>
<tr>
<td>cp /opt/OpenShift/OpenShift.local.config/master/admin.kubeconfig ~/.kube/config</td>
</tr>
<tr>
<td>#重复覆盖</td>
</tr>
<tr>
<td><a href="./media/image15.png">./media/image15.png</a></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>命令登陆</li>
</ul>
<table>
<thead>
<tr>
<th>oc login -u system:admin</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image16.png">./media/image16.png</a>  oc whoami</td>
</tr>
<tr>
<td><a href="./media/image17.png">./media/image17.png</a></td>
</tr>
<tr>
<td>oc get node</td>
</tr>
<tr>
<td><a href="./media/image18.png">./media/image18.png</a></td>
</tr>
</tbody>
</table>
<h2 id="添加Router"><a href="#添加Router" class="headerlink" title="添加Router"></a>添加Router</h2><table>
<thead>
<tr>
<th>#Router是OpenShift集群中的一个重要组件，它是外部访问集群内容器应用的入口。 #集群外部的请求都会到达Router,由Router分发到具体的容器中。</th>
</tr>
</thead>
<tbody>
<tr>
<td># Router组件需要读取集群的信息，所以它需要关联一个系统账号Service Account，并为这个账号授权。</td>
</tr>
<tr>
<td>oc login –u system:admin</td>
</tr>
<tr>
<td>oc project default</td>
</tr>
<tr>
<td><a href="./media/image19.png">./media/image19.png</a></td>
</tr>
<tr>
<td>#配置权限策略</td>
</tr>
<tr>
<td>oadm policy add-scc-to-user privileged system:serviceaccount:default:router</td>
</tr>
<tr>
<td>#创建Router #在实际生产时，为了达到高可用的效果，可以通过设置–replicas创建多个Router实例防止单点失效。</td>
</tr>
<tr>
<td>oadm router router –replicas=1 –service-account=router</td>
</tr>
<tr>
<td><a href="./media/image20.png">./media/image20.png</a></td>
</tr>
<tr>
<td>#查看Router状态</td>
</tr>
<tr>
<td>oc get pod –n default</td>
</tr>
<tr>
<td>ss -ltn\</td>
<td>egrep -w ‘80\</td>
<td>443’</td>
</tr>
<tr>
<td><a href="./media/image21.png">./media/image21.png</a></td>
</tr>
<tr>
<td>#Router就是一个运行在容器里的Haproxy #用户可以创建route对象，称为route规则，一个route规则会与一个service相关联，并且绑定一个域名。 #route规则会被Router加载。当用户通过指定的域名访问应用时，域名会被解析并指向Router所在的计算节点上。Router获取这个请求后，会根据route规则定义转发给与这个域名对应的service后端相关联的Pod容器实例。</td>
</tr>
<tr>
<td>#Router负责将集群外的请求转发到集群的容器。</td>
</tr>
<tr>
<td>#Service负责将集群内的请求转发到指定的容器。</td>
</tr>
<tr>
<td>#一个对外，一个对内。</td>
</tr>
</tbody>
</table>
<h2 id="添加Registry"><a href="#添加Registry" class="headerlink" title="添加Registry"></a>添加Registry</h2><ul>
<li>这里的Registry是部署集群内部的Docker镜像仓库。从功能上来说，它与其他诸如DockerHub没有本质上的区别，只是这个内部镜像仓库会存储由Source<br>to<br>Image（S2I）创建的镜像。S2I的工作是辅助将应用的源代码转换成可以部署的Docker镜像。</li>
</ul>
<table>
<thead>
<tr>
<th><strong>一个典型的S2I流程包括如下：</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>用户输入源代码仓库的地址。</td>
</tr>
</tbody>
</table>
<ol>
<li><p>用户选择S2I构建的基础镜像（Builder镜像）。OpenShift提供了多种编程语言的Builder镜像，用户也可以定制自己的Builder镜像，并发布到服务目录中。</p>
</li>
<li><p>系统或用户触发S2I构建。OpenShift将实例化S2I构建执行器。</p>
</li>
<li><p>S2I构建执行器将从用户指定的代码仓库下载源代码。</p>
</li>
<li><p>S2I构建执行器实例化Builder镜像，并将代码注入Builder镜像中。</p>
</li>
<li><p>Builder镜像将根据预定义的逻辑执行源代码的编译、构建并完成部署。</p>
</li>
<li><p>S2I构建执行器将完成操作的Builder镜像并生成新的Docker镜像。</p>
</li>
<li><p>S2I构建执行器将新的镜像推送到OpenShift内部的镜像仓库中。</p>
</li>
<li><p>S2I构建执行器更新该次构建相关的Image Stream信息。</p>
</li>
</ol>
<p>S2I还可以接受Dockerfile以及二进制文件作为构建的输入。用户甚至可以完全自定义构建逻辑。</p>
<ul>
<li>开始添加</li>
</ul>
<table>
<thead>
<tr>
<th>#以管理员登陆，并切换到default Project</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc login -u system:admin</td>
</tr>
<tr>
<td>oc project default</td>
</tr>
<tr>
<td>#部署Registry</td>
</tr>
<tr>
<td>oadm registry –config=/opt/OpenShift/OpenShift.local.config/master/admin.kubeconfig –service-account=registry</td>
</tr>
<tr>
<td><a href="./media/image22.png">./media/image22.png</a></td>
</tr>
<tr>
<td>#查看状态</td>
</tr>
<tr>
<td>oc get pod -n default</td>
</tr>
<tr>
<td><a href="./media/image23.png">./media/image23.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>添加非HTTPS验证</li>
</ul>
<table>
<thead>
<tr>
<th>#这里部署的Registry没有启用Https，所以需要修改主机上Docker的配置，让Docker能以非Https的方式连接到Registry。</th>
</tr>
</thead>
<tbody>
<tr>
<td>vi /etc/sysconfig/docker</td>
</tr>
<tr>
<td>OPTIONS变量追加” –insecure-registry=172.30.0.0/16”</td>
</tr>
<tr>
<td>#172.30.0.0/16是在master-config.yaml里定义的服务网络的默认值，如果需要修改，则master-config.yaml和/etc/sysconfig/docker需要一致修改。</td>
</tr>
<tr>
<td><a href="./media/image24.png">./media/image24.png</a></td>
</tr>
<tr>
<td>#重启Docker</td>
</tr>
<tr>
<td>systemctl restart docker</td>
</tr>
</tbody>
</table>
<h2 id="添加Image-Stream"><a href="#添加Image-Stream" class="headerlink" title="添加Image Stream"></a>添加Image Stream</h2><table>
<thead>
<tr>
<th>#Image Stream是一组镜像的集合，可以在一个Image Stream中定义一些名称及标签（tag），并定义这些名字及标签指向的具体镜像。 #使用Image Stream的目的是方便地将一组相关联的镜像进行整合管理和使用。 #OpenShift默认为用户定义了一系列开箱即用的Image Stream。</th>
</tr>
</thead>
<tbody>
<tr>
<td>#以管理员登陆，并切换到OpenShift Project #OpenShift是一个特殊的项目，在这个项目下创建的所有Image Stream及Template对集群内所有的用户和项目可见。</td>
</tr>
<tr>
<td>oc login -u system:admin</td>
</tr>
<tr>
<td>oc project openshift</td>
</tr>
<tr>
<td>#导入Image Stream</td>
</tr>
<tr>
<td>curl -k <a href="https://raw.githubusercontent.com/OpenShift/origin/v1.3.0/examples/image-streams/image-streams-centos7.json\" target="_blank" rel="noopener">https://raw.githubusercontent.com/OpenShift/origin/v1.3.0/examples/image-streams/image-streams-centos7.json\</a></td>
<td>oc create -f - -n OpenShift</td>
</tr>
<tr>
<td><a href="./media/image25.png">./media/image25.png</a></td>
</tr>
<tr>
<td>#查看Image Stream对象</td>
</tr>
<tr>
<td>oc get is -n openshift</td>
</tr>
<tr>
<td><a href="./media/image26.png">./media/image26.png</a></td>
</tr>
<tr>
<td>#web console验证</td>
</tr>
<tr>
<td>#登录web console，重新建立工程，可以在界面上看到导入Image Stream之后的可用镜像列表</td>
</tr>
<tr>
<td><a href="./media/image27.png">./media/image27.png</a></td>
</tr>
</tbody>
</table>
<h2 id="添加Template"><a href="#添加Template" class="headerlink" title="添加Template"></a>添加Template</h2><table>
<thead>
<tr>
<th>#为了满足用户对复杂应用部署的需求，提供应用部署的效率，OpenShift引入了应用部署模板（Template）的概念。 #通过Template，可以定义一个或多个需要部署的镜像，定义依赖的对象，定义可供用户输入的配置参数项。</th>
</tr>
</thead>
<tbody>
<tr>
<td>#以管理员登录，并切换到OpenShift工程。</td>
</tr>
<tr>
<td>oc login -u system:admin</td>
</tr>
<tr>
<td>oc project openshift</td>
</tr>
<tr>
<td>#以cakephp-mysql模版为例</td>
</tr>
<tr>
<td>oc create -f <a href="https://raw.githubusercontent.com/OpenShift/origin/v1.3.0/examples/quickstarts/cakephp-mysql.json" target="_blank" rel="noopener">https://raw.githubusercontent.com/OpenShift/origin/v1.3.0/examples/quickstarts/cakephp-mysql.json</a> -n openshift</td>
</tr>
<tr>
<td>#<a href="https://github.com/OpenShift/origin/tree/release-1.3/examples/quickstarts下有官方提供的一系列模版可用" target="_blank" rel="noopener">https://github.com/OpenShift/origin/tree/release-1.3/examples/quickstarts下有官方提供的一系列模版可用</a> #最新3.6版本：<a href="https://github.com/OpenShift/origin/tree/release-3.6/examples/quickstarts" target="_blank" rel="noopener">https://github.com/OpenShift/origin/tree/release-3.6/examples/quickstarts</a></td>
</tr>
<tr>
<td><a href="./media/image28.png">./media/image28.png</a></td>
</tr>
<tr>
<td>#查看模版信息</td>
</tr>
<tr>
<td>oc get template -n openshift</td>
</tr>
<tr>
<td><a href="./media/image29.png">./media/image29.png</a></td>
</tr>
<tr>
<td>#查看模版json信息</td>
</tr>
<tr>
<td>oc get template cakephp-mysql-example -o json -n openshift</td>
</tr>
<tr>
<td>#web console验证</td>
</tr>
<tr>
<td><a href="./media/image30.png">./media/image30.png</a></td>
</tr>
</tbody>
</table>
<h2 id="模版部署应用"><a href="#模版部署应用" class="headerlink" title="模版部署应用"></a>模版部署应用</h2><table>
<thead>
<tr>
<th>#新建Project</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image31.png">./media/image31.png</a></td>
</tr>
<tr>
<td>#过滤cake，选中cakephp-mysql-example模版</td>
</tr>
<tr>
<td><a href="./media/image32.png">./media/image32.png</a></td>
</tr>
<tr>
<td>#指定主机名</td>
</tr>
<tr>
<td>#本地修改hosts #172.16.142.132 php.apps.example.com</td>
</tr>
<tr>
<td><a href="./media/image33.png">./media/image33.png</a></td>
</tr>
<tr>
<td>#创建</td>
</tr>
<tr>
<td><a href="./media/image34.png">./media/image34.png</a></td>
</tr>
<tr>
<td>#部署完成页面</td>
</tr>
<tr>
<td><a href="./media/image35.png">./media/image35.png</a></td>
</tr>
<tr>
<td>#单机”Continue to overview”</td>
</tr>
<tr>
<td>#跳转到项目的概览页面。Openshif会在后台创建相应的对象，并下载相关的镜像。 #由于CakePHP应用涉及一个镜像构建的过程，即Source to Image，所以构建速度较慢。</td>
</tr>
<tr>
<td><a href="./media/image36.png">./media/image36.png</a></td>
</tr>
<tr>
<td>#由于网络原因，这里从github拉代码失败了</td>
</tr>
<tr>
<td><a href="./media/image37.png">./media/image37.png</a></td>
</tr>
<tr>
<td><a href="./media/image38.png">./media/image38.png</a></td>
</tr>
</tbody>
</table>
<h1 id="应用的构建与部署"><a href="#应用的构建与部署" class="headerlink" title=" 应用的构建与部署"></a> 应用的构建与部署</h1><h2 id="JAVA应用容器化"><a href="#JAVA应用容器化" class="headerlink" title="JAVA应用容器化"></a>JAVA应用容器化</h2><ul>
<li><p>执行容器化的环境为Centos7.2</p>
</li>
<li><p>Github项目地址：<a href="https://github.com/nichochen/mybank-demo-maven" target="_blank" rel="noopener">https://github.com/nichochen/mybank-demo-maven</a></p>
</li>
</ul>
<table>
<thead>
<tr>
<th>#安装git和maven</th>
</tr>
</thead>
<tbody>
<tr>
<td>yum install git maven -y</td>
</tr>
<tr>
<td>#下载源码</td>
</tr>
<tr>
<td>cd /opt/</td>
</tr>
<tr>
<td>git clone <a href="https://github.com/nichochen/mybank-demo-maven.git" target="_blank" rel="noopener">https://github.com/nichochen/mybank-demo-maven.git</a></td>
</tr>
<tr>
<td>#编译及构建应用</td>
</tr>
<tr>
<td>cd mybank-demo-maven/</td>
</tr>
<tr>
<td>mvn package</td>
</tr>
<tr>
<td><a href="./media/image39.png">./media/image39.png</a></td>
</tr>
<tr>
<td>#构建完毕。会在target目录下生成一个WAR包ROOT.war</td>
</tr>
<tr>
<td><a href="./media/image40.png">./media/image40.png</a></td>
</tr>
<tr>
<td>#选择Tomcat7官方镜像pull到本地</td>
</tr>
<tr>
<td>docker pull tomcat:7.0.70-jre7-alpine</td>
</tr>
<tr>
<td>#编写Dockerfile，把构建好的应用部署包拷贝到发布目录</td>
</tr>
<tr>
<td>cat Docekrfile FROM tomcat:7.0.70-jre7-alpine ADD ./target/ROOT.war /usr/local/tomcat/webapps/mybank.war</td>
</tr>
<tr>
<td><a href="./media/image41.png">./media/image41.png</a></td>
</tr>
<tr>
<td>#执行Docker Build构建镜像</td>
</tr>
<tr>
<td>docker build -t mybank-tomcat .</td>
</tr>
<tr>
<td><a href="./media/image42.png">./media/image42.png</a></td>
</tr>
<tr>
<td>#查看生成的新镜像</td>
</tr>
<tr>
<td>docker images \</td>
<td>grep mybank-tomcat</td>
</tr>
<tr>
<td><a href="./media/image43.png">./media/image43.png</a></td>
</tr>
<tr>
<td>#测试run镜像</td>
</tr>
<tr>
<td>docker run -it –rm -p 8080:8080 mybank-tomcat</td>
</tr>
<tr>
<td>#访问IP:8080即可看到访问页面</td>
</tr>
<tr>
<td>#推送镜像到私有仓库</td>
</tr>
<tr>
<td>#打tag</td>
</tr>
<tr>
<td>docker tag mybank-tomcat:latest registry.your-registry.com/mybank-tomcat:latest</td>
</tr>
<tr>
<td>#推送</td>
</tr>
<tr>
<td>docker push registry.your-registry.com/mybank-tomcat:latest</td>
</tr>
</tbody>
</table>
<h2 id="OpenShift的构建与部署"><a href="#OpenShift的构建与部署" class="headerlink" title="OpenShift的构建与部署"></a>OpenShift的构建与部署</h2><h3 id="2-1-快速构建部署一个应用"><a href="#2-1-快速构建部署一个应用" class="headerlink" title="2.1. 快速构建部署一个应用"></a>2.1. 快速构建部署一个应用</h3><table>
<thead>
<tr>
<th>#web console创建一个应用</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image44.png">./media/image44.png</a></td>
</tr>
<tr>
<td>#选择“wildfly:10”的Builder镜像</td>
</tr>
<tr>
<td><a href="./media/image45.png">./media/image45.png</a></td>
</tr>
<tr>
<td>#输入示例项目代码地址：<a href="https://github.com/nichochen/mybank-demo-maven" target="_blank" rel="noopener">https://github.com/nichochen/mybank-demo-maven</a></td>
</tr>
<tr>
<td><a href="./media/image46.png">./media/image46.png</a></td>
</tr>
<tr>
<td><a href="./media/image47.png">./media/image47.png</a></td>
</tr>
<tr>
<td>#如果构建日志报错，尝试手动先pull需要的镜像 #docker pull OpenShift/wildfly-100-centos7</td>
</tr>
<tr>
<td>#日中可以看到构建的过程</td>
</tr>
<tr>
<td><a href="./media/image48.png">./media/image48.png</a></td>
</tr>
<tr>
<td>#构建到最后可以看到是将生成的镜像推送到内部的镜像仓库中（Registry）</td>
</tr>
<tr>
<td><a href="./media/image49.png">./media/image49.png</a></td>
</tr>
<tr>
<td>#完成状态</td>
</tr>
<tr>
<td><a href="./media/image50.png">./media/image50.png</a></td>
</tr>
<tr>
<td>#查看本地Docker镜像列表，可以看到mybank镜像</td>
</tr>
<tr>
<td>docker images \</td>
<td>grep mybank</td>
</tr>
<tr>
<td><a href="./media/image51.png">./media/image51.png</a></td>
</tr>
<tr>
<td>#查看应用状态</td>
</tr>
<tr>
<td>oc get pod -n mybank</td>
</tr>
<tr>
<td><a href="./media/image52.png">./media/image52.png</a></td>
</tr>
</tbody>
</table>
<h3 id="2-2-镜像构建介绍"><a href="#2-2-镜像构建介绍" class="headerlink" title="2.2. 镜像构建介绍"></a>2.2. 镜像构建介绍</h3><ul>
<li><strong>Build Config</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#在上一个实例中，单击create后，OpenShift会创建名为“Build Config”的对象。</th>
</tr>
</thead>
<tbody>
<tr>
<td>#查询创建的Build Config</td>
</tr>
<tr>
<td>oc get bc</td>
</tr>
<tr>
<td><a href="./media/image53.png">./media/image53.png</a></td>
</tr>
<tr>
<td>#查询bc中的具体配置信息</td>
</tr>
<tr>
<td>oc get bc mybank -o yaml</td>
</tr>
<tr>
<td><a href="./media/image54.png">./media/image54.png</a></td>
</tr>
<tr>
<td>#红框中标示出bc的重要内容 #定义构建输出到了一个mybank:latest的Image Stream #源代码仓库地址 #前面制定的Builder镜像信息，没有指向某个实际的镜像，而是指向了一个Image Stream（用Image Stream的概念来管理一组镜像的集合，定义多个镜像名称和Tag，再指向实际的Docker镜像），</td>
</tr>
<tr>
<td>#查看定义的刚生成名为mybank的Image Stream</td>
</tr>
<tr>
<td>oc get is mybank</td>
</tr>
<tr>
<td><a href="./media/image55.png">./media/image55.png</a></td>
</tr>
<tr>
<td>#查看详细信息 #该Image Stream实际指向了OpenShift/wildfly-100-centos7\@sha256:968b2cb9f11c347fbaa6830d33386e5d31b283bdf0060b4cff865e14f5064848</td>
</tr>
<tr>
<td>oc describe is mybank</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Build</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#Build Config只是静态的配置信息，OpenShift根据这个配置信息可以触发多次实际构建实例，构建的实例称为Build。 #一个Build Config可以被多次触发，生成多个Build</th>
</tr>
</thead>
<tbody>
<tr>
<td>#查看mybank的build构建记录</td>
</tr>
<tr>
<td>oc get build</td>
</tr>
<tr>
<td><a href="./media/image56.png">./media/image56.png</a></td>
</tr>
<tr>
<td>#查看build构建详细信息，这里的信息与web console下看到的日志信息相同</td>
</tr>
<tr>
<td>oc log build/mybank-1</td>
</tr>
<tr>
<td>#可以通过之前的Build Config再执行一个新的Build构建</td>
</tr>
<tr>
<td>oc start-build mybank</td>
</tr>
<tr>
<td>oc get build</td>
</tr>
<tr>
<td><a href="./media/image57.png">./media/image57.png</a></td>
</tr>
<tr>
<td>#查看新的构建状态</td>
</tr>
<tr>
<td>oc logs build/mybank-2</td>
</tr>
</tbody>
</table>
<h3 id="2-3-镜像部署介绍"><a href="#2-3-镜像部署介绍" class="headerlink" title="2.3. 镜像部署介绍"></a>2.3. 镜像部署介绍</h3><ul>
<li><strong>Deployment Config</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#当前文的Build构建完成，就是S2I流程完成后，生成的应用镜像被推送到内部的镜像仓库，同时更新相关的Image Stream，之后OpenShift就会触发一次部署，部署也有配置定义对象：Deployment Config。DC描述了镜像部署的参数和要求</th>
</tr>
</thead>
<tbody>
<tr>
<td>#查看Deployment Config列表</td>
</tr>
<tr>
<td>oc get dc</td>
</tr>
<tr>
<td><a href="./media/image58.png">./media/image58.png</a></td>
</tr>
<tr>
<td>#查看dc详细定义</td>
</tr>
<tr>
<td>oc get dc mybank -o yaml</td>
</tr>
<tr>
<td>#在Deployment Config中，可以定义容器运行的细节配置 ，如容器的启动命令，容器可用的CPU和内存配置等等。</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Deploy</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#每个DC可以被多次触发，每一次触发称为一个Deploy #每一次Deploy都会生成一个Replication Controller，用以监控容器的状态，RC实际是kubernetes中的一个组件，其负责监控容器的实际数量</th>
</tr>
</thead>
<tbody>
<tr>
<td>#查看Replication Controller</td>
</tr>
<tr>
<td>oc get rc</td>
</tr>
<tr>
<td><a href="./media/image59.png">./media/image59.png</a></td>
</tr>
</tbody>
</table>
<h3 id="2-4-服务的连通性介绍（Service-amp-Route）"><a href="#2-4-服务的连通性介绍（Service-amp-Route）" class="headerlink" title="2.4. 服务的连通性介绍（Service &amp; Route）"></a>2.4. 服务的连通性介绍（Service &amp; Route）</h3><ul>
<li><strong>Service</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#在部署应用时，OpenShift会自动生成DC对应的Service</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc get svc</td>
</tr>
<tr>
<td>oc describe svc mybank</td>
</tr>
<tr>
<td><a href="./media/image60.png">./media/image60.png</a></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Route</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#基于Service，OpenShift同时也自动创建了对应的Route</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc get route</td>
</tr>
<tr>
<td>oc describe route mybank</td>
</tr>
<tr>
<td><a href="./media/image61.png">./media/image61.png</a></td>
</tr>
<tr>
<td>#修改指定域名</td>
</tr>
<tr>
<td>oc edit route</td>
</tr>
</tbody>
</table>
<h2 id="弹性伸缩"><a href="#弹性伸缩" class="headerlink" title="弹性伸缩"></a>弹性伸缩</h2><ul>
<li><strong>Replication Controller</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#正常情况下，每一个部署的应用的容器实例数量在其Deployment Config中定义，OpenShift会为每次的部署实例化一个RC(可以不定义RC)</th>
</tr>
</thead>
<tbody>
<tr>
<td>#查看当前mybank应用活动实例数为1</td>
</tr>
<tr>
<td>oc get pod</td>
</tr>
<tr>
<td><a href="./media/image62.png">./media/image62.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>扩展容器实例</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#通过RC，可以调整实例存着的数量</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc scale dc mybank –replicas=2</td>
</tr>
<tr>
<td><a href="./media/image63.png">./media/image63.png</a></td>
</tr>
<tr>
<td>#可以看到pod变为2个，rc中的数量也已经被更新为2</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>状态自服务</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#删除运行中的pod，测试rc恢复pod</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc delete pod mybank-1-5ek1w</td>
</tr>
<tr>
<td>oc get pod</td>
</tr>
<tr>
<td><a href="./media/image64.png">./media/image64.png</a></td>
</tr>
<tr>
<td>#可以看到其中一个pod被删除的瞬间，一个新的pod同时被创建了</td>
</tr>
<tr>
<td>#RC的作用就是监控容器状态，并始终保持正常运行的pod数量</td>
</tr>
</tbody>
</table>
<h2 id="应用更新发布"><a href="#应用更新发布" class="headerlink" title="应用更新发布"></a>应用更新发布</h2><ul>
<li><strong>触发更新构建</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#Build Config信息中可以看到定义了两个WebHook触发器 #Generic WebHook #GitHub WebHook</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc get bc mybank -o yaml</td>
</tr>
<tr>
<td><a href="./media/image65.png">./media/image65.png</a></td>
</tr>
<tr>
<td>#在web console中可以看到实际的调用地址</td>
</tr>
<tr>
<td><a href="./media/image66.png">./media/image66.png</a></td>
</tr>
<tr>
<td># Generic WebHook使用，只需向调用地址发送POST请求即可触发</td>
</tr>
<tr>
<td>curl -k -X POST <a href="https://172.16.142.132:8443/oapi/v1/namespaces/mybank/buildconfigs/mybank/webhooks/a62289d1f901ea32/generic" target="_blank" rel="noopener">https://172.16.142.132:8443/oapi/v1/namespaces/mybank/buildconfigs/mybank/webhooks/a62289d1f901ea32/generic</a></td>
</tr>
<tr>
<td><a href="./media/image67.png">./media/image67.png</a></td>
</tr>
<tr>
<td><a href="./media/image68.png">./media/image68.png</a></td>
</tr>
<tr>
<td>#post请求发送到OpenShift之后，一个新的build就产生并开始执行</td>
</tr>
<tr>
<td>#GitHub WebHook需要用户登陆到GitHub</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>更新部署</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#构建结束后，更新部署被触发，OpenShift有Rolling（滚动更新）和Recreate（重新创建）两种，默认是Rolling</th>
</tr>
</thead>
<tbody>
<tr>
<td>#更新策略在Deployment Config中定义</td>
</tr>
<tr>
<td>oc get dc mybank -o yaml</td>
</tr>
<tr>
<td><a href="./media/image69.png">./media/image69.png</a></td>
</tr>
</tbody>
</table>
<h1 id="持续集成与部署"><a href="#持续集成与部署" class="headerlink" title=" 持续集成与部署"></a> 持续集成与部署</h1><h2 id="部署Jenkins服务"><a href="#部署Jenkins服务" class="headerlink" title="部署Jenkins服务"></a>部署Jenkins服务</h2><ul>
<li><p>OpenShift提供了集成OpenShift插件的Jenkins容器镜像和部署模版</p>
</li>
<li><p>默认提供两个Jenkins部署模版：Jenkins-ephemeral（测试验证用）和jenkins-persistent（持久化支持）</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>#以dev用户登陆</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc login -u dev</td>
</tr>
<tr>
<td>#创建名为ci的新项目用来部署jenkins</td>
</tr>
<tr>
<td>oc new-project ci</td>
</tr>
<tr>
<td><a href="./media/image70.png">./media/image70.png</a></td>
</tr>
<tr>
<td>#下载并导入Jenkins模版Jenkins-ephemeral</td>
</tr>
<tr>
<td>oc create -f <a href="https://raw.githubusercontent.com/openshift/origin/v1.3.0/examples/jenkins/jenkins-ephemeral-template.json" target="_blank" rel="noopener">https://raw.githubusercontent.com/openshift/origin/v1.3.0/examples/jenkins/jenkins-ephemeral-template.json</a></td>
</tr>
<tr>
<td><a href="./media/image71.png">./media/image71.png</a></td>
</tr>
<tr>
<td>oc get template</td>
</tr>
<tr>
<td><a href="./media/image72.png">./media/image72.png</a></td>
</tr>
<tr>
<td>#为默认的Service Account用户添加权限，使Jenkins容器有足够的权限操作项目的配置及执行部署</td>
</tr>
<tr>
<td>oc policy add-role-to-user edit -z default</td>
</tr>
<tr>
<td>#通过Jenkins模版部署Jenkins服务，指定默认管理员密码为123\@abcd</td>
</tr>
<tr>
<td>oc new-app –template=jenkins-ephemeral –param=JENKINS_PASSWORD=123\@abcd</td>
</tr>
<tr>
<td><a href="./media/image73.png">./media/image73.png</a></td>
</tr>
<tr>
<td>#时间稍长，应为需要联网下载jenkins镜像 #查看服务状态</td>
</tr>
<tr>
<td>oc get pod</td>
</tr>
<tr>
<td><a href="./media/image74.png">./media/image74.png</a></td>
</tr>
<tr>
<td>#Jenkins模版中定义了Route，通过指定的主机名（配好hosts，手动添加解析将jenkins-ci.router.default.svc.cluster.local指向Router服务所在的IP地址），便可以访问Jenkins服务</td>
</tr>
<tr>
<td>oc get route</td>
</tr>
<tr>
<td><a href="./media/image75.png">./media/image75.png</a></td>
</tr>
<tr>
<td>#访问Jenkins服务 #<a href="https://jenkins-ci.router.default.svc.cluster.local/" target="_blank" rel="noopener">https://jenkins-ci.router.default.svc.cluster.local/</a> #admin:123\@abcd</td>
</tr>
<tr>
<td><a href="./media/image76.png">./media/image76.png</a></td>
</tr>
<tr>
<td><a href="./media/image77.png">./media/image77.png</a></td>
</tr>
</tbody>
</table>
<h2 id="触发项目构建"><a href="#触发项目构建" class="headerlink" title="触发项目构建"></a>触发项目构建</h2><ul>
<li>Jenkins部署好了之后，就可以在jenkins上出发mybank的S2I构建</li>
</ul>
<table>
<thead>
<tr>
<th>#为jenkins授权，可以在mybank项目中执行操作</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc policy add-role-to-user edit system:serviceaccount:ci:jenkins -n mybank</td>
</tr>
<tr>
<td>#创建Jenkins项目，Jenkins界面操作</td>
</tr>
<tr>
<td><a href="./media/image78.png">./media/image78.png</a></td>
</tr>
<tr>
<td><a href="./media/image79.png">./media/image79.png</a></td>
</tr>
<tr>
<td><a href="./media/image80.png">./media/image80.png</a></td>
</tr>
<tr>
<td><a href="./media/image81.png">./media/image81.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>手动触发构建</li>
</ul>
<table>
<thead>
<tr>
<th>#Jenkins控制台首页</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="./media/image82.png">./media/image82.png</a></td>
</tr>
<tr>
<td>#查看构建输出</td>
</tr>
<tr>
<td><a href="./media/image83.png">./media/image83.png</a></td>
</tr>
</tbody>
</table>
<h1 id="应用数据持久化"><a href="#应用数据持久化" class="headerlink" title=" 应用数据持久化"></a> 应用数据持久化</h1><h2 id="持久化镜像仓库"><a href="#持久化镜像仓库" class="headerlink" title="持久化镜像仓库"></a>持久化镜像仓库</h2><ul>
<li><strong>检查挂载点</strong></li>
</ul>
<table>
<thead>
<tr>
<th>oc login -u system:admin</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc project default</td>
</tr>
<tr>
<td>oc get pod</td>
</tr>
<tr>
<td><a href="./media/image84.png">./media/image84.png</a></td>
</tr>
<tr>
<td>#通过oc volume查看Registry组件的DC关于Volume的定义，创建了一个Volume Mounts对象registry-storage，这个挂载点指向了/registry目录 #我们要做的就是给registry-storage这个挂载点挂上一个持久化后端</td>
</tr>
<tr>
<td>oc get dc</td>
</tr>
<tr>
<td>oc volumes dc/docker-registry –all</td>
</tr>
<tr>
<td><a href="./media/image85.png">./media/image85.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>备份数据</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#当前Registry容器内的/registry目录下已有很多镜像相关的文件</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc get po</td>
</tr>
<tr>
<td>oc rsh docker-registry-1-akri7 ‘du’ ‘-sh’ /registry</td>
</tr>
<tr>
<td><a href="./media/image86.png">./media/image86.png</a></td>
</tr>
<tr>
<td>#需要先备份这些文件，通过ocrsync命令同步到宿主机上</td>
</tr>
<tr>
<td>mkdir /root/backup cd /root/backup</td>
</tr>
<tr>
<td>oc rsync docker-registry-1-akri7:/registry .</td>
</tr>
<tr>
<td><a href="./media/image87.png">./media/image87.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>创建存储</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#选用NFS作为后端存储，生产环境可使用GlusterFS，Ceph</th>
</tr>
</thead>
<tbody>
<tr>
<td>#创建一个NFS共享目录</td>
</tr>
<tr>
<td>mkdir -p /exports/pv0001 yum -y install nfs-utils rpcbind chown nfsnobody:nfsnobody /exports/ -R echo “/exports/pv0001 *(rw,sync,all_squash)” >> /etc/exports systemctl start rpcbind exportfs -r systemctl start nfs-server showmount -e 127.0.0.1</td>
</tr>
<tr>
<td>setenforce 0</td>
</tr>
<tr>
<td>getenforce</td>
</tr>
<tr>
<td>#测试挂载</td>
</tr>
<tr>
<td>[root\@master ~]# mount 172.16.142.132:exports/pv0001 /mnt/ [root\@master ~]# [root\@master ~]# [root\@master ~]# touch /mnt/test [root\@master ~]# ls /mnt/ test [root\@master ~]# rm -rf /mnt/test [root\@master ~]# umount /mnt/</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>创建持久化卷</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#创建pv.json文件</th>
</tr>
</thead>
<tbody>
<tr>
<td>[root\@master ~]# more pv.json { “apiVersion”: “v1”, “kind”: “PersistentVolume”, “metadata”: { “name”: “pv0001” }, “spec”: { “capacity”: { “storage”: “5Gi” }, “accessModes”: [ “ReadWriteOnce” ], “nfs”: { “path”: “/exports/pv0001”, “server”: “172.16.142.132” }, “persistentVolumeReclaimPolicy”: “Retain” } }</td>
</tr>
<tr>
<td>oc create -f pv.json</td>
</tr>
<tr>
<td>oc get pv</td>
</tr>
<tr>
<td><a href="./media/image88.png">./media/image88.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>创建持久化卷请求</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#创建pvc.json文件</th>
</tr>
</thead>
<tbody>
<tr>
<td>[root\@master ~]# more pvc.json { “apiVersion”: “v1”, “kind”: “PersistentVolumeClaim”, “metadata”: { “name”: “docker-registry-claim” }, “spec”: { “accessModes”: [ “ReadWriteOnce” ], “resources”: { “requests”: { “storage”: “3Gi” } } } }</td>
</tr>
<tr>
<td>oc create -f pvc.json</td>
</tr>
<tr>
<td>oc get pvc</td>
</tr>
<tr>
<td>oc get pv</td>
</tr>
<tr>
<td><a href="./media/image89.png">./media/image89.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li><strong>关联持久化卷请求</strong></li>
</ul>
<table>
<thead>
<tr>
<th>#将备份的文件恢复到创建的nfs目录中</th>
</tr>
</thead>
<tbody>
<tr>
<td>mv /root/backup/registry/* /exports/pv0001/</td>
</tr>
<tr>
<td>chown nfsnobody:nfsnobody /exports/ -R</td>
</tr>
<tr>
<td>#测试删除Registry容器，RC将会重新创建它</td>
</tr>
<tr>
<td>oc get pod</td>
</tr>
<tr>
<td>oc delete pod docker-registry-1-akri7</td>
</tr>
<tr>
<td><a href="./media/image90.png">./media/image90.png</a></td>
</tr>
<tr>
<td>#容器启动后，再次检查/registry目录，发现数据消失，应为之前并没有做持久化</td>
</tr>
<tr>
<td>oc rsh docker-registry-1-fqtfp ‘du’ ‘-sh’ /registry</td>
</tr>
<tr>
<td><a href="./media/image91.png">./media/image91.png</a></td>
</tr>
<tr>
<td>#为Registry的容器添加持久化卷请求，docker-registry-claim，并与挂载点registry-storage关联</td>
</tr>
<tr>
<td>oc volume dc/docker-registry –add –name=registry-storage -t pvc –claim-name=docker-registry-claim –overwrite</td>
</tr>
<tr>
<td>#DC被修改后，Openshift会创建新的容器实例</td>
</tr>
<tr>
<td>#再次检查容器的/registry目录，发现目录数据恢复了</td>
</tr>
<tr>
<td>oc volume dc/docker-registry –add –name=registry-storage -t pvc –claim-name=docker-registry-claim –overwrite</td>
</tr>
<tr>
<td>oc get pod</td>
</tr>
<tr>
<td>oc rsh docker-registry-2-f36ot ‘du’ ‘-sh’ /registry</td>
</tr>
<tr>
<td><a href="./media/image92.png">./media/image92.png</a></td>
</tr>
</tbody>
</table>
<h1 id="监控与日志管理"><a href="#监控与日志管理" class="headerlink" title=" 监控与日志管理"></a> 监控与日志管理</h1><h2 id="容器集群数据采集"><a href="#容器集群数据采集" class="headerlink" title="容器集群数据采集"></a>容器集群数据采集</h2><h2 id="容器集群日志管理"><a href="#容器集群日志管理" class="headerlink" title="容器集群日志管理"></a>容器集群日志管理</h2><ul>
<li><p>使用开源方案EFK：Elasticsearch，Fluentd，Kibana</p>
<ul>
<li><p>Fluentd：将以容器方式运行在集群的各个节点上。读取宿主机上的/var/log/message及/var/lib/docker目录下的系统及容器日志信息，并对信息进行格式化成JSON格式，最好发送给Elasticsearch</p>
</li>
<li><p>Elasticsearch：收到日志信息后，存储信息并建立索引</p>
</li>
<li><p>Kibana：提供图形界面用用户检索分析Elasticsearch中的日志</p>
</li>
<li><p>AuthProxy：为Kibana实现身份验证，与Openshift Web实现单点登陆</p>
</li>
<li><p>Curator：管理和优化Elasticsearch索引</p>
</li>
</ul>
</li>
<li><p>创建部署模版</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>#管理员身份登陆</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc login –u system:admin</td>
</tr>
<tr>
<td>#下载部署模版并解压</td>
</tr>
<tr>
<td>wget <a href="https://github.com/openshift/origin-aggregated-logging/archive/v1.3.0.tar.gz" target="_blank" rel="noopener">https://github.com/openshift/origin-aggregated-logging/archive/v1.3.0.tar.gz</a></td>
</tr>
<tr>
<td>tar zxvf v1.3.0.tar.gz</td>
</tr>
<tr>
<td>#导入日志部署模版</td>
</tr>
<tr>
<td>oc create -n openshift -f origin-aggregated-logging-1.3.0/deployer/deployer.yaml</td>
</tr>
</tbody>
</table>
<ul>
<li>配置Service Account</li>
</ul>
<table>
<thead>
<tr>
<th>#新建项目</th>
</tr>
</thead>
<tbody>
<tr>
<td>oadm new-project logging –node-selector=””</td>
</tr>
<tr>
<td>oc project logging</td>
</tr>
<tr>
<td>#创建应用部署的Service Account账号</td>
</tr>
<tr>
<td>oc new-app logging-deployer-account-template</td>
</tr>
<tr>
<td>#配置服务授权</td>
</tr>
<tr>
<td>oadm policy add-cluster-role-to-user oauth-editor \ system:serviceaccount:logging:logging-deployer</td>
</tr>
<tr>
<td>oadm policy add-scc-to-user privileged \ system:serviceaccount:logging:aggregated-logging-fluentd</td>
</tr>
<tr>
<td>oadm policy add-cluster-role-to-user cluster-reader \ system:serviceaccount:logging:aggregated-logging-fluentd</td>
</tr>
</tbody>
</table>
<ul>
<li>配置证书</li>
</ul>
<table>
<thead>
<tr>
<th>#创建应用组件使用的证书，并创建Secret对象loging-deployer存储对应的证书。改Secret对象会被部署引用</th>
</tr>
</thead>
<tbody>
<tr>
<td>oadm ca create-server-cert \ –signer-cert=/opt/openshift/openshift.local.config/master/ca.crt \ –signer-key=/opt/openshift/openshift.local.config/master/ca.key \ –signer-serial=/opt/openshift/openshift.local.config/master/ca.serial.txt \ –hostnames=’kibana.apps.example.com’ \ –cert=/etc/opt/openshift/openshift.local.config/master/kibana.crt \ –key=/etc//opt/openshift/openshift.local.config/master/kibana.key</td>
</tr>
<tr>
<td>oc create secret generic logging-deployer \ –from-file kibana.crt=/etc/opt/openshift/openshift.local.config/master/kibana.crt \ –from-file kibana.key=/etc/opt/openshift/openshift.local.config/master/kibana.key</td>
</tr>
<tr>
<td><a href="./media/image93.png">./media/image93.png</a></td>
</tr>
<tr>
<td><a href="./media/image94.png">./media/image94.png</a></td>
</tr>
</tbody>
</table>
<ul>
<li>部署日志组件模版</li>
</ul>
<table>
<thead>
<tr>
<th>#设置集群部署参数，创建一个Config Map对象logging-deployer为日志组件的部署设定参数 #参数指定Kinbana域名，Openshift集群Master地址，Elasticsearch的实例数及使用的内存大小</th>
</tr>
</thead>
<tbody>
<tr>
<td>oc create configmap logging-deployer \ –from-literal kibana-hostname=kibana.apps.example.com \ –from-literal public-master-url=<a href="https://master.example.com:8443" target="_blank" rel="noopener">https://master.example.com:8443</a> \ –from-literal es-cluster-size=1 \ –from-literal es-instance-ram=1G</td>
</tr>
<tr>
<td><a href="./media/image95.png">./media/image95.png</a></td>
</tr>
<tr>
<td>#通过模版部署日志组件</td>
</tr>
<tr>
<td>#网络原因，提前下好所需镜像</td>
</tr>
<tr>
<td>for i in openshift/origin-logging-curator:v1.3.0 \ openshift/origin-logging-fluentd:v1.3.0 \ openshift/origin-logging-auth-proxy:v1.3.0 \ openshift/origin-logging-deployment:v1.3.0 \ openshift/origin-logging-elasticsearch:v1.3.0 \ openshift/origin-logging-kibana:v1.3.0 ; do docker pull \$i; done</td>
</tr>
<tr>
<td>oc new-app logging-deployer-template \ –param IMAGE_VERSION=v1.3.0 \ –param IMAGE_PREFIX=openshift/origin- \ –param MODE=install</td>
</tr>
</tbody>
</table>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Chen Fei</p>
              <p class="site-description motion-element" itemprop="description">把我的过程记录下来，以免以后忘了</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">68</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">15</span>
                    <span class="site-state-item-name">分类</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">40</span>
                    <span class="site-state-item-name">标签</span>
                  
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chen Fei</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动 v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Mist</a> v6.3.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



  










  





  

  

  

  

  
  

  

  

  

  

  

</body>
</html>
